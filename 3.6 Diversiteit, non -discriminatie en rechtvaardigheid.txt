Deze paragraaf bevat vier onderdelen binnen het verbod op discriminatie.
De risico’s die worden geadresseerd zijn discriminatie op basis van
beschermde persoonskenmerken, andere data dan beschermde
persoonskenmerken die leiden tot discriminatie, het gebruiken van proxy
variabelen die leiden tot discriminatie en bias in het algoritme. Een van de
maatregelen is bij het vaststellen van verdacht onderscheid als ultieme
tegenmaatregel het (tijdelijk) stopzetten van het algoritme. De normen,
risico's en maatregelen voor diversiteit, non-discriminatie en
rechtvaardigheid komen voort uit de Grondwet, EVRM, Algemene wet gelijke
behandeling.
3.6.1 Norm: Verbod op ongelijke behandeling in gelijke omstandigheden.
Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid,
ras, geslacht of op welke grond dan ook, is niet toegestaan. (*)
1 Risico:
Toepassing van het model leidt tot discriminatie op basis van beschermde
persoonskenmerken.

Maatregel:
Stel vast of bij het doel, design of de uitkomst van het algoritme sprake is
van (direct of indirect) onderscheid. Maak bij de uitkomst ook gebruik van
controlevariabelen (bijvoorbeeld nationaliteit/ras). Bepaal of er een
wettelijke uitzondering of een objectieve rechtvaardiging is. Maak de
consequentie expliciet en leg deze op het juiste niveau vast. Neem indien
nodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)
stopzetten van het algoritme.
Toelichting:
Er is sprake van een objectieve rechtvaardiging als sprake is van een
legitiem doel en het middel dat wordt gebruikt om het doel te bereiken is
passend, noodzakelijk en evenredig. Om te bepalen of een algoritme
verboden onderscheid maakt, moet worden bekeken of door het algoritme
sprake is van een ongelijke behandeling van een persoon of groep personen
in verhouding tot anderen in een vergelijkbare situatie.
Bron: Grondwet Art. 1 EVRM Art. 1 en 14 Algemene wet gelijke behandeling,
Protocol 12.
Risico:
Andere data dan beschermde persoonskenmerken leiden tot discriminatie
in de uitkomsten.
Maatregelen:
• Zorg voor gelijke mate van vertegenwoordiging relevante groepen.
Selecteer een afgebakende toepassing om het systeem te testen;
zorg dat deze afgebakende toepassing representatief is voor het
gehele domein waarop het AI-systeem later wordt ingezet. Maak de
consequenties expliciet en leg deze op het juiste niveau vast. Neem
indien nodig tegenmaatregelen. Een ultieme tegenmaatregel kan
zijn het (tijdelijk) stopzetten van het algoritme.
• Documenteer de mate van afhankelijkheid van historische data.
Weeg af of de geconstateerde afhankelijkheid wenselijk is en of deze
op discriminatie duidt. Maak de consequenties expliciet en leg deze
op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Een
ultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het
algoritme.
Toelichting:
• Onvoldoende representativiteit in de trainingsdata kan leiden tot
ongelijke uitkomsten.
• Onvoldoende representativiteit in de trainingsdata kan leiden tot
ongelijke uitkomsten. Kan bij voorspellende algoritmen ook leiden
tot ongewenste feedbackloops. (Gebruik van data van bijvoorbeeld
vroegere surveillance en criminaliteitscijfers in nieuwe algoritmen
algoritmen tot link aan wijken, personen met een

immigratieachtergrond. Indien het geval, is dit niet representatief
en neutraal)
Bronnen:
Grondwet Art. 1.
EVRM Art. 1 en 14 Algemene wet gelijke behandeling, Protocol 12.
Artikel 9 AVG.
Artikel 14 EVRM jo. 21 HvEU jo. 1 GW.
3 Risico: Het gebruik van proxy variabelen leidt tot indirecte discriminatie.
Maatregel:
Identificeer bij een onrechtmatigheid in de uitkomst van het algoritme
ogenschijnlijk neutrale data (proxies). Maak de consequenties expliciet en
leg deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen.
Een ultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het
algoritme.
Toelichting:
Ogenschijnlijk neutrale data die op het eerste gezicht bijvoorbeeld geen
enkele link hebben met afkomst of nationaliteit kunnen leiden tot indirect
onderscheid op grond van ras of nationaliteit. Voorbeelden zijn postcode,
hoogte van inkomen, hoogte van inkomensafhankelijke toeslagen,
kinderopvang door een gastouderbureau met een ‘homogeen’
klantenbestand, een familielid in het buitenland, kenteken en
laaggeletterdheid.
Bron: Artikel 1 lid 1 sub c Awgb.
4 Risico: Bias in het algoritme leidt tot discriminatie.
Maatregelen:
1. Beoordeel of de geconstateerde bias wenselijk is en of deze op
discriminatie duidt. Maak de consequenties expliciet en leg deze op het
juiste niveau vast. Neem indien nodig tegenmaatregelen. Een ultieme
tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme. Van
belang bij de gemeten bias die duidt op discriminatie is het kijken vanuit
wetgeving én wenselijkheid.
2. Documenteer in de functionele eisen de definitie van acceptabele bias. In
de documentatie waarin deze eisen tot meetbare prestatiecriteria zijn
uitgewerkt is te vinden welke fairness metrics hierbij horen. Maak de
consequenties expliciet. Eerst moet duidelijk worden wat eerlijk is voor het
proces. Dan kunnen fairness metrics worden opgesteld om eerlijkheid te
meten.
3. Documenteer in de functionele eisen de methoden van voorkomen,
detecteren en corrigeren van bias. Maak de consequenties expliciet.
Documentatie van de aanpak van bias bevordert de controleerbaarheid.

4. Documenteer in de functionele eisen de doelstelling voor en definitie van
de verschillende groepen en gewenste prestatie van het model voor deze
groepen. Maak de consequenties expliciet en bespreek dit in het ethisch
gesprek. De keuze voor een gewenste prestatie per groep is een ethische
afweging.
5. Documenteer de mate van bias in de (trainings)data, dataverzameling en
het model. Maak de consequenties expliciet en leg deze op het juiste niveau
vast. Neem indien nodig tegenmaatregelen. Een ultieme tegenmaatregel
kan zijn het (tijdelijk) stopzetten van het algoritme. Bias in de trainingsdata,
regels in het model en de beslissing van de eindgebruiker kunnen leiden tot
bias. Bias in de inputdata kan doorwerken tot bias in de uitkomst.
6. Beoordeel tijdens de ontwikkeling van het model of een verschil bestaat
tussen prestatie van het model voor verschillende subgroepen. Maak de
consequenties expliciet en leg deze op het juiste niveau vast. Neem indien
nodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)
stopzetten van het algoritme. Een model kan gemiddeld goed presteren,
maar kan voor bepaalde subgroepen die minder in de testset aanwezig
waren verkeerde uitkomsten geven.
7. Beoordeel of de uitkomstbias van de productiedata voor de verschillende
subgroepen voldoet aan de productiecriteria. Doe dit ook met een testset
gedurende het ontwikkelproces. Maak de consequenties expliciet en leg
deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Een
ultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme.
Tijdens de ontwikkeling van het model kunnen methoden om bias te
corrigeren helpen om aan de prestatiecriteria te voldoen. Testresultaten op
de uitkomstbias tijdens het ontwikkelen zijn ook wenselijk. Merk op dat voor
het meten van uitkomstbias alleen de inputdata en uitkomst van het model
nodig is. Uitkomstbias kan zonder gelabelde dataset gemeten worden.
Toelichting:
In de hierboven beschreven maatregelen is te zien dat veel vormen van bias
bestaan die elk op hun eigen manier tegengegaan kunnen worden. Vandaar
dat de toelichting hierop direct achter de maatregel is geplaatst.
Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1, 1.5.