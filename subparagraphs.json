[{"waarde_nr": "3.2", "waarde_naam": "Menselijke controle", "norm_nr": "3.2.1", "norm_naam": "Er is een gepaste mate van menselijke controle voor het specifieke algoritme en de specifieke gebruikssituatie", "norm_tekst": "Norm: Er is een gepaste mate van menselijke controle voor het specifieke\nalgoritme en de specifieke gebruikssituatie.\nRisico: Gebruikers kunnen geen onderbouwde, autonome beslissingen\nnemen ten aanzien van een algoritmisch systeem.\nMaatregel: Zorg dat bij uitsluitend geautomatiseerde besluitvorming wordt\nvoldaan aan de vereisten die volgen uit artikel 22 van de AVG. Zie hierbij\nnorm 3.4.10\nZorg dat goede toezichtmechanismen zijn gewaarborgd. Deze kunnen\nworden bereikt door middel van human-in-the-loop (HITL), human-on-the-\nloop (HOTL) en human-in-command (HIC) benaderingen.\n\u2022 HITL: het vermogen van de mens om in te grijpen in elke\nbeslissingscyclus van het systeem dat wordt gemonitord. Dit\nbetekent dat bij elke beslissing een mens actief betrokken is\ngeweest.\n\u2022 HOTL: menselijke interventie tijdens de ontwerp- en monitoringcycli\nvan het op AI gebaseerde systeem. De rol van de mens hierbij is\ndie van toezichthouder op een in principe automatisch verlopend\nproces, waarbij de mens de mogelijkheid heeft om in grijpen\n\u2022 HIC: het vermogen van de mens om toezicht te houden op de\nalgehele activiteit van het AI-systeem, inclusief de bredere\neconomische, maatschappelijke, juridische en ethische gevolgen\nervan, en ervoor te zorgen dat beslissingen die door het AI-systeem\nworden geproduceerd, door de mens kunnen worden overschreven.\nDe ultieme controle over het proces blijft in deze opzet altijd in\nhanden van een mens.\nAfhankelijk van de toepassing die wordt overwogen, kunnen mechanismen\nworden ontworpen die een van de bovengenoemde niveaus van menselijk\ntoezicht ondersteunen. De tot nu toe voorgestelde methoden zijn\ngrotendeels domein-specifiek, omdat gebruikers-algoritme-interfaces\nvari\u00ebren afhankelijk van de mogelijkheden en achtergrond van de op AI\ngebaseerde oplossing\nIndien het algoritme of de gebruikssituatie zelflerend of autonoom is, dan is\nhet van belang om specifiekere controle- en toezichtmechanismen in te\nstellen:\n\u2022 Zorg voor detectie- en responsmechanismen om te controleren of\ner iets mis kan gaan\n\u2022 Zorg voor een \"stopknop\" of procedure waarmee een activiteit\nindien nodig veilig kan worden afgebroken.\n\u2022 Beoordeel of met deze procedure het proces volledig wordt\nafgebroken, het gedeeltelijk wordt afgebroken of de controle wordt\novergedragen aan een mens\n", "norm_risico_namen": ["Norm: Er is een gepaste mate van menselijke controle voor het specifieke algoritme en de specifieke gebruikssituatie Risico: Gebruikers kunnen geen onderbouwde, autonome beslissingennemen ten aanzien van een algoritmisch systeem."], "norm_risico_teksten": ["Norm: Er is een gepaste mate van menselijke controle voor het specifieke algoritme en de specifieke gebruikssituatie Risico: Gebruikers kunnen geen onderbouwde, autonome beslissingennemen ten aanzien van een algoritmisch systeem.Maatregel: Zorg dat bij uitsluitend geautomatiseerde besluitvorming wordtvoldaan aan de vereisten die volgen uit artikel 22 van de AVG. Zie hierbijnorm 3.4.10Zorg dat goede toezichtmechanismen zijn gewaarborgd. Deze kunnenworden bereikt door middel van human-in-the-loop (HITL), human-on-the-loop (HOTL) en human-in-command (HIC) benaderingen.\u2022 HITL: het vermogen van de mens om in te grijpen in elkebeslissingscyclus van het systeem dat wordt gemonitord. Ditbetekent dat bij elke beslissing een mens actief betrokken isgeweest.\u2022 HOTL: menselijke interventie tijdens de ontwerp- en monitoringcyclivan het op AI gebaseerde systeem. De rol van de mens hierbij isdie van toezichthouder op een in principe automatisch verlopendproces, waarbij de mens de mogelijkheid heeft om in grijpen\u2022 HIC: het vermogen van de mens om toezicht te houden op dealgehele activiteit van het AI-systeem, inclusief de bredereeconomische, maatschappelijke, juridische en ethische gevolgenervan, en ervoor te zorgen dat beslissingen die door het AI-systeemworden geproduceerd, door de mens kunnen worden overschreven.De ultieme controle over het proces blijft in deze opzet altijd inhanden van een mens.Afhankelijk van de toepassing die wordt overwogen, kunnen mechanismenworden ontworpen die een van de bovengenoemde niveaus van menselijktoezicht ondersteunen. De tot nu toe voorgestelde methoden zijngrotendeels domein-specifiek, omdat gebruikers-algoritme-interfacesvari\u00ebren afhankelijk van de mogelijkheden en achtergrond van de op AIgebaseerde oplossingIndien het algoritme of de gebruikssituatie zelflerend of autonoom is, dan ishet van belang om specifiekere controle- en toezichtmechanismen in testellen:\u2022 Zorg voor detectie- en responsmechanismen om te controleren ofer iets mis kan gaan\u2022 Zorg voor een \"stopknop\" of procedure waarmee een activiteitindien nodig veilig kan worden afgebroken.\u2022 Beoordeel of met deze procedure het proces volledig wordtafgebroken, het gedeeltelijk wordt afgebroken of de controle wordtovergedragen aan een mens"]}, {"waarde_nr": "3.3", "waarde_naam": "Technische robuustheid en veiligheid", "norm_nr": "3.3.1", "norm_naam": "De informatiebeveiliging is op orde", "norm_tekst": "Norm: De informatiebeveiliging is op orde. (*)\nRisico: Wanneer de informatiebeveiliging m.b.t. de omgeving waarin het\nalgoritme ontwikkeld en gebruikt wordt onvoldoende op orde is, brengt dit\ngrote risico's met zich mee voor de beschikbaarheid, de integriteit en de\nvertrouwelijkheid van gegevens.\nMaatregel: Zorg ervoor dat zowel bij de ontwikkeling van het algoritme als\nbij het gebruik ervan wordt voldaan aan de eisen uit de BIO. (*)\nToelichting: De gebruikte technische infrastructuur, de inrichting en het\nbeheer ervan moeten voldoen aan de daarvoor geldende eisen op het gebied\nvan informatiebeveiliging. Voor de overheid zijn deze vastgelegd in de BIO.\nDe BIO is in zijn geheel van toepassing.\nBron: Baseline Informatieveiligheid Overheid.", "norm_risico_namen": ["Norm: De informatiebeveiliging is op orde Risico: Wanneer de informatiebeveiliging m.b.t. de omgeving waarin hetalgoritme ontwikkeld en gebruikt wordt onvoldoende op orde is, brengt ditgrote risico's met zich mee voor de beschikbaarheid, de integriteit en devertrouwelijkheid van gegevens."], "norm_risico_teksten": ["Norm: De informatiebeveiliging is op orde Risico: Wanneer de informatiebeveiliging m.b.t. de omgeving waarin hetalgoritme ontwikkeld en gebruikt wordt onvoldoende op orde is, brengt ditgrote risico's met zich mee voor de beschikbaarheid, de integriteit en devertrouwelijkheid van gegevens.Maatregel: Zorg ervoor dat zowel bij de ontwikkeling van het algoritme alsbij het gebruik ervan wordt voldaan aan de eisen uit de BIO. (*)Toelichting: De gebruikte technische infrastructuur, de inrichting en hetbeheer ervan moeten voldoen aan de daarvoor geldende eisen op het gebiedvan informatiebeveiliging. Voor de overheid zijn deze vastgelegd in de BIO.De BIO is in zijn geheel van toepassing.Bron: Baseline Informatieveiligheid Overheid."]}, {"waarde_nr": "3.3", "waarde_naam": "Technische robuustheid en veiligheid", "norm_nr": "3.3.2", "norm_naam": "De data die worden gebruikt is eenduidig en representatief voor de populatie waarop het algoritme wordt toegepast", "norm_tekst": "Norm: De data die worden gebruikt is eenduidig en representatief voor de\npopulatie waarop het algoritme wordt toegepast.\n1. Risico: Door training van het model met een niet-evenwichtige dataset\npresteert het model in de praktijk minder goed dan bij de tests.\nMaatregel: Leg vast welke keuzes zijn gemaakt bij het samenstellen van de\ndatasets waarmee het algoritme getraind is en bij de waarborging van de\nkwaliteit ervan. Omschrijf de populatie waarop het algoritme wordt\ntoegepast dusdanig duidelijk dat deze statistisch gevalideerd kan worden.\nLeg statistieken vast van inputdatasets die zijn gebruikt bij de onderbouwing\nvan data- en modelkeuzes. Bij de keuze voor training- en testdata in de\nontwikkelfase moet zowel under- als overfitting worden voorkomen.\nToelichting: De dataset waarmee het algoritme wordt getraind moet\npassend zijn bij het beoogde gebruik ervan. Trainings-, test- en\nvalidatiedata moeten zijn afgestemd op de populatie waarop het algoritme\nwordt toegepast, inclusief daarin voorkomende subgroepen.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 2.1\u00a7100.\n\n2. Risico: De input- en outputdata voldoen qua kwaliteit, volledigheid en\nbetrouwbaarheid niet aan de functionele eisen, waardoor verkeerde\nbeslissingen kunnen worden genomen.\nMaatregel: Stel documentatie op waarin de eisen aan de input- en\noutputdata zijn opgenomen en implementeer structurele controles om dit te\ntoetsen. Ga voor alle inputdata na of deze tijdig, volledig en definitief\nbeschikbaar is, een herleidbare afkomst heeft, consistent is gecodeerd en\nduidelijke metadata bij de variabelen bevat. Kijk daarnaast naar het risico\nvan datavervuiling in het proces.\nToelichting: Als input- en outputdata van onvoldoende kwaliteit zijn of een\nandere betekenis hebben dan verwacht, dan zijn de uitkomsten van het\nmodel onbetrouwbaar, wat kan leiden tot verkeerde beslissingen.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.3.", "norm_risico_namen": ["Norm: De data die worden gebruikt is eenduidig en representatief voor de populatie waarop het algoritme wordt toegepast Risico: Door training van het model met een niet-evenwichtige datasetpresteert het model in de praktijk minder goed dan bij de tests.", "Norm: De data die worden gebruikt is eenduidig en representatief voor de populatie waarop het algoritme wordt toegepast Risico: De input- en outputdata voldoen qua kwaliteit, volledigheid enbetrouwbaarheid niet aan de functionele eisen, waardoor verkeerdebeslissingen kunnen worden genomen."], "norm_risico_teksten": ["Norm: De data die worden gebruikt is eenduidig en representatief voor de populatie waarop het algoritme wordt toegepast Risico: Door training van het model met een niet-evenwichtige datasetpresteert het model in de praktijk minder goed dan bij de tests.Maatregel: Leg vast welke keuzes zijn gemaakt bij het samenstellen van dedatasets waarmee het algoritme getraind is en bij de waarborging van dekwaliteit ervan. Omschrijf de populatie waarop het algoritme wordttoegepast dusdanig duidelijk dat deze statistisch gevalideerd kan worden.Leg statistieken vast van inputdatasets die zijn gebruikt bij de onderbouwingvan data- en modelkeuzes. Bij de keuze voor training- en testdata in deontwikkelfase moet zowel under- als overfitting worden voorkomen.Toelichting: De dataset waarmee het algoritme wordt getraind moetpassend zijn bij het beoogde gebruik ervan. Trainings-, test- envalidatiedata moeten zijn afgestemd op de populatie waarop het algoritmewordt toegepast, inclusief daarin voorkomende subgroepen.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 2.1\u00a7100.", "Norm: De data die worden gebruikt is eenduidig en representatief voor de populatie waarop het algoritme wordt toegepast Risico: De input- en outputdata voldoen qua kwaliteit, volledigheid enbetrouwbaarheid niet aan de functionele eisen, waardoor verkeerdebeslissingen kunnen worden genomen.Maatregel: Stel documentatie op waarin de eisen aan de input- enoutputdata zijn opgenomen en implementeer structurele controles om dit tetoetsen. Ga voor alle inputdata na of deze tijdig, volledig en definitiefbeschikbaar is, een herleidbare afkomst heeft, consistent is gecodeerd enduidelijke metadata bij de variabelen bevat. Kijk daarnaast naar het risicovan datavervuiling in het proces.Toelichting: Als input- en outputdata van onvoldoende kwaliteit zijn of eenandere betekenis hebben dan verwacht, dan zijn de uitkomsten van hetmodel onbetrouwbaar, wat kan leiden tot verkeerde beslissingen.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.3."]}, {"waarde_nr": "3.3", "waarde_naam": "Technische robuustheid en veiligheid", "norm_nr": "3.3.3", "norm_naam": "Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor het wordt ingezet", "norm_tekst": "Norm: Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor\nhet wordt ingezet.\n1. Risico: Het algoritme dat wordt gebruikt is niet geschikt voor het doel\nwaarvoor het wordt ingezet.\nMaatregel: Documenteer de grenzen van de toepasbaarheid van het\nalgoritme en de voorwaarden waaronder het kan worden gebruikt.\nToelichting: Het moet duidelijk zijn onder welke voorwaarden een algoritme\nwel of niet gebruikt kan worden. Denk hierbij bijvoorbeeld aan eisen voor\nde verdeling van data of afwijkingen van de productieset ten opzichte van\nde testset. Deze voorwaarden moeten dusdanig helder zijn gedocumenteerd\ndat deze informatie ook toegankelijk is voor medewerkers die niet bij de\nontwikkeling van het algoritme betrokken waren.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1, 1.2.\n2. Risico: De hyperparameters zijn niet goed gekozen, waardoor niet goed\ngestuurd kan worden op het leerproces en het model suboptimaal presteert.\nMaatregel: Leg de keuze voor de hyperparameters vast en onderbouw deze,\nbijvoorbeeld in Git en/of het technisch of functioneel ontwerp. Het uitvoeren\nvan een peer review (vierogenprincipe) kan hiervan onderdeel zijn.\nToelichting: Een hyperparameter is een parameter waarmee kan worden\ngestuurd op een trainings- en leerproces.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2.\n", "norm_risico_namen": ["Norm: Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor het wordt ingezet Risico: Het algoritme dat wordt gebruikt is niet geschikt voor het doelwaarvoor het wordt ingezet.", "Norm: Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor het wordt ingezet Risico: De hyperparameters zijn niet goed gekozen, waardoor niet goedgestuurd kan worden op het leerproces en het model suboptimaal presteert."], "norm_risico_teksten": ["Norm: Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor het wordt ingezet Risico: Het algoritme dat wordt gebruikt is niet geschikt voor het doelwaarvoor het wordt ingezet.Maatregel: Documenteer de grenzen van de toepasbaarheid van hetalgoritme en de voorwaarden waaronder het kan worden gebruikt.Toelichting: Het moet duidelijk zijn onder welke voorwaarden een algoritmewel of niet gebruikt kan worden. Denk hierbij bijvoorbeeld aan eisen voorde verdeling van data of afwijkingen van de productieset ten opzichte vande testset. Deze voorwaarden moeten dusdanig helder zijn gedocumenteerddat deze informatie ook toegankelijk is voor medewerkers die niet bij deontwikkeling van het algoritme betrokken waren.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1, 1.2.", "Norm: Het algoritme dat wordt gebruikt is geschikt voor het doel waarvoor het wordt ingezet Risico: De hyperparameters zijn niet goed gekozen, waardoor niet goedgestuurd kan worden op het leerproces en het model suboptimaal presteert.Maatregel: Leg de keuze voor de hyperparameters vast en onderbouw deze,bijvoorbeeld in Git en/of het technisch of functioneel ontwerp. Het uitvoerenvan een peer review (vierogenprincipe) kan hiervan onderdeel zijn.Toelichting: Een hyperparameter is een parameter waarmee kan wordengestuurd op een trainings- en leerproces.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2."]}, {"waarde_nr": "3.3", "waarde_naam": "Technische robuustheid en veiligheid", "norm_nr": "3.3.4", "norm_naam": "De uitkomsten van het algoritme zijn eenduidig en betrouwbaar", "norm_tekst": "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar.\n1 Risico: Als trainings-, validatie- en testdata door elkaar lopen (\"data\nleakage\"), kan dit leiden tot overfitting, waardoor het model beter lijkt te\npresteren dan in werkelijkheid het geval is.\nMaatregel: Scheid de datasets voor training, validatie en testen en leg vast\nwelke datasets voor welk doel gebruikt zijn. Let in het bijzonder op wanneer\nhet model ge\u00fcpdatet wordt aan de hand van (deels) eerder gebruikte data.\nToelichting: Vermenging van trainings-, validatie- en testdata kan leiden tot\noverfitting van het model, waardoor het goed werkt voor de data waarmee\nhet is getraind, maar niet geschikt is voor nieuwe observaties. Het gevolg\nvan overfitting is dat prestaties van het model worden overschat. Dit komt\ndoordat het lijkt alsof wordt getest op basis van data die het model nog niet\neerder heeft gezien, terwijl in werkelijkheid wordt getest met data waarmee\nhet model ook is getraind.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 2.1\u00a7100.\n2. Risico: Het doel van het algoritme, de functionele eisen van het model en\nde performance metrics sluiten onvoldoende op elkaar aan, waardoor niet\nkan worden beoordeeld of het voldoende presteert en of de kwaliteit ervan\nop orde is.\nMaatregel: Documenteer alle prestatiecriteria, inclusief de relatie met de\ndoelstellingen en de functionele eisen van het algoritme. Bewaar\ntestresultaten waaruit blijkt dat het algoritme aan de criteria voldoet.\nToelichting: De functionele eisen moeten zijn uitgewerkt in meetbare eisen,\nonder andere met betrekking tot de prestaties, robuustheid, bias en\nuitlegbaarheid van het model. Deze eisen moeten passen bij de\nmodelspecifieke context.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1 t/m 1.6.\n3. Risico: Door veranderingen in de data presteert het algoritme niet meer\nzoals verwacht.\nMaatregel: Leg voor elk algoritme de kwaliteits- en prestatiedoelen vast.\nStel een procesbeschrijving op voor het monitoren hiervan. Evalueer bij\nveranderingen in de data of het algoritme nog aan de vastgestelde doelen\nvoldoet en neem indien nodig maatregelen.\nToelichting: Veranderingen in de data kunnen ertoe leiden dat de prestaties\nvan het algoritme achteruitgaan. Wanneer veranderingen in de data niet\ndirect duidelijk zijn, zal periodiek een evaluatie moeten plaatsvinden.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 1.3.\n\n4. Risico: Beslissingen worden genomen op basis van outputdata die\nverkeerd zijn begrepen.\nMaatregel: Zorg voor een eenduidige beschrijving van alle variabelen. Neem\nindien nodig extra toelichting op in de metadata.\nToelichting: De interpretatie van de uitkomsten van het model moet\neenduidig zijn en onafhankelijk van de persoon die de beoordeling uitvoert.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.4.", "norm_risico_namen": ["Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Als trainings-, validatie- en testdata door elkaar lopen (\"dataleakage\"), kan dit leiden tot overfitting, waardoor het model beter lijkt tepresteren dan in werkelijkheid het geval is.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Het doel van het algoritme, de functionele eisen van het model ende performance metrics sluiten onvoldoende op elkaar aan, waardoor nietkan worden beoordeeld of het voldoende presteert en of de kwaliteit ervanop orde is.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Door veranderingen in de data presteert het algoritme niet meerzoals verwacht.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Beslissingen worden genomen op basis van outputdata dieverkeerd zijn begrepen."], "norm_risico_teksten": ["Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Als trainings-, validatie- en testdata door elkaar lopen (\"dataleakage\"), kan dit leiden tot overfitting, waardoor het model beter lijkt tepresteren dan in werkelijkheid het geval is.Maatregel: Scheid de datasets voor training, validatie en testen en leg vastwelke datasets voor welk doel gebruikt zijn. Let in het bijzonder op wanneerhet model ge\u00fcpdatet wordt aan de hand van (deels) eerder gebruikte data.Toelichting: Vermenging van trainings-, validatie- en testdata kan leiden totoverfitting van het model, waardoor het goed werkt voor de data waarmeehet is getraind, maar niet geschikt is voor nieuwe observaties. Het gevolgvan overfitting is dat prestaties van het model worden overschat. Dit komtdoordat het lijkt alsof wordt getest op basis van data die het model nog nieteerder heeft gezien, terwijl in werkelijkheid wordt getest met data waarmeehet model ook is getraind.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 2.1\u00a7100.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Het doel van het algoritme, de functionele eisen van het model ende performance metrics sluiten onvoldoende op elkaar aan, waardoor nietkan worden beoordeeld of het voldoende presteert en of de kwaliteit ervanop orde is.Maatregel: Documenteer alle prestatiecriteria, inclusief de relatie met dedoelstellingen en de functionele eisen van het algoritme. Bewaartestresultaten waaruit blijkt dat het algoritme aan de criteria voldoet.Toelichting: De functionele eisen moeten zijn uitgewerkt in meetbare eisen,onder andere met betrekking tot de prestaties, robuustheid, bias enuitlegbaarheid van het model. Deze eisen moeten passen bij demodelspecifieke context.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1 t/m 1.6.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Door veranderingen in de data presteert het algoritme niet meerzoals verwacht.Maatregel: Leg voor elk algoritme de kwaliteits- en prestatiedoelen vast.Stel een procesbeschrijving op voor het monitoren hiervan. Evalueer bijveranderingen in de data of het algoritme nog aan de vastgestelde doelenvoldoet en neem indien nodig maatregelen.Toelichting: Veranderingen in de data kunnen ertoe leiden dat de prestatiesvan het algoritme achteruitgaan. Wanneer veranderingen in de data nietdirect duidelijk zijn, zal periodiek een evaluatie moeten plaatsvinden.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.2, 1.3.", "Norm: De uitkomsten van het algoritme zijn eenduidig en betrouwbaar Risico: Beslissingen worden genomen op basis van outputdata dieverkeerd zijn begrepen.Maatregel: Zorg voor een eenduidige beschrijving van alle variabelen. Neemindien nodig extra toelichting op in de metadata.Toelichting: De interpretatie van de uitkomsten van het model moeteenduidig zijn en onafhankelijk van de persoon die de beoordeling uitvoert.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.4."]}, {"waarde_nr": "3.3", "waarde_naam": "Technische robuustheid en veiligheid", "norm_nr": "3.3.5", "norm_naam": "De continu\u00efteit van het algoritme is gewaarborgd", "norm_tekst": "Norm: De continu\u00efteit van het algoritme is gewaarborgd.\n1 Risico: De organisatie is voor de data en/of het gebruik van het algoritme\nafhankelijk van derden en kan daardoor de reproduceerbaarheid, het\nprestatieniveau en de continu\u00efteit ervan niet garanderen.\nMaatregel: Alle gebruikte data moeten traceerbaar of reproduceerbaar zijn.\nIn geval van uitbesteding van het beheer aan derden moeten hierover\nheldere afspraken gemaakt worden gemaakt.\nToelichting: De data en het model zijn bij voorkeur in eigen beheer.\nWanneer dit niet mogelijk is, moeten afspraken zijn gemaakt om de\nfunctionele eisen die hieraan gesteld zijn te waarborgen.\nBron: EC/AI HLEG April 2019 hoofdstuk II 1.7.\n2 Risico: Er vindt na ingebruikname van het algoritme onvoldoende\nmonitoring plaats op de werking ervan, waardoor fouten of ongewenste\neffecten in de toepassing van het algoritme niet of niet tijdig worden\nopgemerkt.\nMaatregel: Richt een proces in rondom monitoring van het algoritme.\nToelichting: Na ingebruikname van een algoritme moet periodiek worden\nbeoordeeld of het nog doet wat het zou moeten doen. Denk hierbij aan\nmonitoring op beschikbaarheid, prestaties/kwaliteit en compliance met\n(actuele) wet- en regelgeving.\nBron: COBIT APO11 / BAI04 / DSS04\n3. Risico: Er is onvoldoende capaciteit beschikbaar in de beheerorganisatie,\nwaardoor benodigde aanpassingen op het algoritme niet of niet tijdig\nworden doorgevoerd.\nMaatregel: Zorg voor heldere afspraken op het gebied van onderhoud en\nbeheer op het algoritme, o.a. met betrekking tot de technische\n\ncomponenten, de gebruikte data, het model en de daarin gebruikte\nparameters.\nToelichting: Het risico bestaat dat bij het in productie nemen van het\nalgoritme onvoldoende aandacht wordt besteed aan de overdracht aan de\nbeheerorganisatie. Gevolg hiervan kan zijn dat in de beheerorganisatie\nonvoldoende capaciteit en/of kennis van het algoritme beschikbaar is om\neventuele aanpassingen tijdig door te voeren.\nBron: COBIT APO09 / APO14 / BAI06.", "norm_risico_namen": ["Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: De organisatie is voor de data en/of het gebruik van het algoritmeafhankelijk van derden en kan daardoor de reproduceerbaarheid, hetprestatieniveau en de continu\u00efteit ervan niet garanderen.", "Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: Er vindt na ingebruikname van het algoritme onvoldoendemonitoring plaats op de werking ervan, waardoor fouten of ongewensteeffecten in de toepassing van het algoritme niet of niet tijdig wordenopgemerkt.", "Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: Er is onvoldoende capaciteit beschikbaar in de beheerorganisatie,waardoor benodigde aanpassingen op het algoritme niet of niet tijdigworden doorgevoerd."], "norm_risico_teksten": ["Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: De organisatie is voor de data en/of het gebruik van het algoritmeafhankelijk van derden en kan daardoor de reproduceerbaarheid, hetprestatieniveau en de continu\u00efteit ervan niet garanderen.Maatregel: Alle gebruikte data moeten traceerbaar of reproduceerbaar zijn.In geval van uitbesteding van het beheer aan derden moeten hieroverheldere afspraken gemaakt worden gemaakt.Toelichting: De data en het model zijn bij voorkeur in eigen beheer.Wanneer dit niet mogelijk is, moeten afspraken zijn gemaakt om defunctionele eisen die hieraan gesteld zijn te waarborgen.Bron: EC/AI HLEG April 2019 hoofdstuk II 1.7.", "Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: Er vindt na ingebruikname van het algoritme onvoldoendemonitoring plaats op de werking ervan, waardoor fouten of ongewensteeffecten in de toepassing van het algoritme niet of niet tijdig wordenopgemerkt.Maatregel: Richt een proces in rondom monitoring van het algoritme.Toelichting: Na ingebruikname van een algoritme moet periodiek wordenbeoordeeld of het nog doet wat het zou moeten doen. Denk hierbij aanmonitoring op beschikbaarheid, prestaties/kwaliteit en compliance met(actuele) wet- en regelgeving.Bron: COBIT APO11 / BAI04 / DSS04", "Norm: De continu\u00efteit van het algoritme is gewaarborgd Risico: Er is onvoldoende capaciteit beschikbaar in de beheerorganisatie,waardoor benodigde aanpassingen op het algoritme niet of niet tijdigworden doorgevoerd.Maatregel: Zorg voor heldere afspraken op het gebied van onderhoud enbeheer op het algoritme, o.a. met betrekking tot de technischecomponenten, de gebruikte data, het model en de daarin gebruikteparameters.Toelichting: Het risico bestaat dat bij het in productie nemen van hetalgoritme onvoldoende aandacht wordt besteed aan de overdracht aan debeheerorganisatie. Gevolg hiervan kan zijn dat in de beheerorganisatieonvoldoende capaciteit en/of kennis van het algoritme beschikbaar is omeventuele aanpassingen tijdig door te voeren.Bron: COBIT APO09 / APO14 / BAI06."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.1", "norm_naam": "Rollen en verantwoordlijkheden m.b.t. de verwerking van persoonsgegevens zijn gespecificeerd", "norm_tekst": "Norm: Rollen en verantwoordlijkheden m.b.t. de verwerking van\npersoonsgegevens zijn gespecificeerd. (*)\nRisico: Rollen en verantwoordelijkheden m.b.t. de verwerking van\npersoonsgegeven in het algoritme zijn niet helder belegd. (*)\nMaatregel:\nGa van alle betrokken partijen na wat hun rol is en documenteer deze. Zorg\nervoor dat met partijen duidelijke afspraken zijn gemaakt.\nToelichting:\nDe verplichtingen uit de AVG zijn van toepassing op de\nverwerkingsverantwoordelijke.\nWanneer een partij samen met een of meerdere andere partijen de doelen\nen essenti\u00eble middelen bepaalt voor de verwerking, dan is er sprake van\ngezamenlijke verwerkingsverantwoordelijkheid. Bij gezamenlijke\nverantwoordelijkheid moeten de partijen onderling duidelijke afspraken\nmaken over wie invulling geef aan de diverse rechten en plichten uit de AVG.\n14 Zoals aangegeven in paragraaf 1.2 zijn er bepaalde sectoren waar een\nafwijkend wettelijk kader geldt. Op deze organisaties is dit hoofdstuk niet\nvan toepassing, maar moet worden voldaan aan de respectievelijke\ngeldende wettelijke kaders zoals de Wpg en de Wjsg.\n15 Handleiding Algemene Verordening Gegevensbescherming (AVG) | Rapport |\nRijksoverheid.nl\n\nVerwerkingsverantwoordelijken schakelen regelmatig personen of\norganisaties in die voor hen persoonsgegevens verwerken. De verwerker\nverwerkt persoonsgegevens uitsluitend ten behoeve van de\nverwerkingsverantwoordelijke. De taken van de verwerker jegens de\nverwerkingsverantwoordelijke moeten in een verwerkersovereenkomst\nworden gespecificeerd.\nBron: Artikel 24,26,27, 28,29 AVG.", "norm_risico_namen": ["Norm: Rollen en verantwoordlijkheden m.b.t. de verwerking van persoonsgegevens zijn gespecificeerd Risico: Rollen en verantwoordelijkheden m.b.t. de verwerking vanpersoonsgegeven in het algoritme zijn niet helder belegd. (*)"], "norm_risico_teksten": ["Norm: Rollen en verantwoordlijkheden m.b.t. de verwerking van persoonsgegevens zijn gespecificeerd Risico: Rollen en verantwoordelijkheden m.b.t. de verwerking vanpersoonsgegeven in het algoritme zijn niet helder belegd. (*)Maatregel:Ga van alle betrokken partijen na wat hun rol is en documenteer deze. Zorgervoor dat met partijen duidelijke afspraken zijn gemaakt.Toelichting:De verplichtingen uit de AVG zijn van toepassing op deverwerkingsverantwoordelijke.Wanneer een partij samen met een of meerdere andere partijen de doelenen essenti\u00eble middelen bepaalt voor de verwerking, dan is er sprake vangezamenlijke verwerkingsverantwoordelijkheid. Bij gezamenlijkeverantwoordelijkheid moeten de partijen onderling duidelijke afsprakenmaken over wie invulling geef aan de diverse rechten en plichten uit de AVG.14 Zoals aangegeven in paragraaf 1.2 zijn er bepaalde sectoren waar eenafwijkend wettelijk kader geldt. Op deze organisaties is dit hoofdstuk nietvan toepassing, maar moet worden voldaan aan de respectievelijkegeldende wettelijke kaders zoals de Wpg en de Wjsg.15 Handleiding Algemene Verordening Gegevensbescherming (AVG) | Rapport |Rijksoverheid.nlVerwerkingsverantwoordelijken schakelen regelmatig personen oforganisaties in die voor hen persoonsgegevens verwerken. De verwerkerverwerkt persoonsgegevens uitsluitend ten behoeve van deverwerkingsverantwoordelijke. De taken van de verwerker jegens deverwerkingsverantwoordelijke moeten in een verwerkersovereenkomstworden gespecificeerd.Bron: Artikel 24,26,27, 28,29 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.2", "norm_naam": "Een gegevensbeschermingseffectbeoordeling / Data Protection Impact Assessment (GEB / DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen", "norm_tekst": "Norm: Een gegevensbeschermingseffectbeoordeling / Data Protection\nImpact Assessment (GEB / DPIA) is verplicht, indien een verwerking van\npersoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten\nen vrijheden van natuurlijke personen. (*)\nRisico: Bij de verwerking van persoonsgegevens zijn de risico's voor de\nrechten en vrijheden van betrokkenen niet bekend en niet gemitigeerd.\nMaatregel:\nBeoordeel of de gegevensverwerking waarschijnlijk een hoog risico voor de\nrechten en vrijheden oplevert voor de mensen van wie gegevens worden\nverwerkt. Met behulp van bijvoorbeeld de Pre-scan DPIA16 of de lijst\nverplichte DPIA van de AP17 kan worden vastgesteld of het uitvoeren van\neen DPIA noodzakelijk is.\nIndien blijkt dat de gegevensverwerking waarschijnlijk een hoog\nprivacyrisico oplevert, dan moet een DPIA worden uitgevoerd.(*) De\nRijksoverheid heeft het Model DPIA Rijksdienst ontwikkeld.18\nToelichting:\nEen DPIA is een beoordeling van de effecten van een voorgenomen\nverwerkingsactiviteit op de bescherming van persoonsgegevens en de\nrechten en vrijheden van betrokkenen. Op basis hiervan worden\nmaatregelen getroffen om deze effecten voor betrokkenen te voorkomen of\nte verkleinen. Hoewel een DPIA een verplichting is op basis van de AVG en\nvoornamelijk ziet op het beoordelen van privacyrisico\u2019s, dient een DPIA dus\nbreder opgevat te worden.\nBron: Artikel 35 AVG.", "norm_risico_namen": ["Norm: Een gegevensbeschermingseffectbeoordeling / Data Protection Impact Assessment (GEB / DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen Risico: Bij de verwerking van persoonsgegevens zijn de risico's voor derechten en vrijheden van betrokkenen niet bekend en niet gemitigeerd."], "norm_risico_teksten": ["Norm: Een gegevensbeschermingseffectbeoordeling / Data Protection Impact Assessment (GEB / DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen Risico: Bij de verwerking van persoonsgegevens zijn de risico's voor derechten en vrijheden van betrokkenen niet bekend en niet gemitigeerd.Maatregel:Beoordeel of de gegevensverwerking waarschijnlijk een hoog risico voor derechten en vrijheden oplevert voor de mensen van wie gegevens wordenverwerkt. Met behulp van bijvoorbeeld de Pre-scan DPIA16 of de lijstverplichte DPIA van de AP17 kan worden vastgesteld of het uitvoeren vaneen DPIA noodzakelijk is.Indien blijkt dat de gegevensverwerking waarschijnlijk een hoogprivacyrisico oplevert, dan moet een DPIA worden uitgevoerd.(*) DeRijksoverheid heeft het Model DPIA Rijksdienst ontwikkeld.18Toelichting:Een DPIA is een beoordeling van de effecten van een voorgenomenverwerkingsactiviteit op de bescherming van persoonsgegevens en derechten en vrijheden van betrokkenen. Op basis hiervan wordenmaatregelen getroffen om deze effecten voor betrokkenen te voorkomen ofte verkleinen. Hoewel een DPIA een verplichting is op basis van de AVG envoornamelijk ziet op het beoordelen van privacyrisico\u2019s, dient een DPIA dusbreder opgevat te worden.Bron: Artikel 35 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.3", "norm_naam": "De verwerking van persoonsgegevens is rechtmatig, behoorlijk en transparant", "norm_tekst": "Norm: De verwerking van persoonsgegevens is rechtmatig, behoorlijk en\ntransparant. (*)\nRisico: De verwerking van persoonsgegevens gebeurt niet rechtmatig,\nbehoorlijk of transparant.\nMaatregel:\nDe betrokkenen zijn ge\u00efnformeerd over de verwerking van\npersoonsgegevens. Bijvoorbeeld middels een privacyverklaring op de\n16 Producten/diensten - cip-overheid\n17 Besluit lijst verplichte DPIA | Autoriteit Persoonsgegevens\n18 Producten/diensten - cip-overheid\n\nwebsite en indien relevant opgenomen in individuele communicatie naar\nbetrokkene(n). (*)\nOrganisaties die gegevens verwerken zoals bedoeld in artikel 22 AVG\nmoeten naast de algemene vereisten nuttige informatie over de\nonderliggende logica verstrekken. Nuttige informatie over de onderliggende\nlogica betreft bijvoorbeeld:\n\u2022 Dat de verstrekte informatie volledig genoeg moet zijn voor de\nbetrokkene om de redenen van het besluit te kunnen begrijpen.\n\u2022 Gedetailleerde informatie over de belangrijkste kenmerken die bij\nde besluitvorming in beschouwing worden genomen, de bron van\ndeze informatie en het belang ervan.\nLeg dit vast in de DPIA.\nToelichting:\nDe inzet van een algoritme is voor de betrokkene vaak onzichtbaar. De mate\nwaarin mensen dergelijke processen begrijpen, verschilt per persoon. Voor\nsommigen kan het moeilijk zijn de complexe technieken te begrijpen.\nBron: Artikel 5, lid 1, onder a AVG, Artikel 12-14 AVG.", "norm_risico_namen": ["Norm: De verwerking van persoonsgegevens is rechtmatig, behoorlijk en transparant Risico: De verwerking van persoonsgegevens gebeurt niet rechtmatig,behoorlijk of transparant."], "norm_risico_teksten": ["Norm: De verwerking van persoonsgegevens is rechtmatig, behoorlijk en transparant Risico: De verwerking van persoonsgegevens gebeurt niet rechtmatig,behoorlijk of transparant.Maatregel:De betrokkenen zijn ge\u00efnformeerd over de verwerking vanpersoonsgegevens. Bijvoorbeeld middels een privacyverklaring op de16 Producten/diensten - cip-overheid17 Besluit lijst verplichte DPIA | Autoriteit Persoonsgegevens18 Producten/diensten - cip-overheidwebsite en indien relevant opgenomen in individuele communicatie naarbetrokkene(n). (*)Organisaties die gegevens verwerken zoals bedoeld in artikel 22 AVGmoeten naast de algemene vereisten nuttige informatie over deonderliggende logica verstrekken. Nuttige informatie over de onderliggendelogica betreft bijvoorbeeld:\u2022 Dat de verstrekte informatie volledig genoeg moet zijn voor debetrokkene om de redenen van het besluit te kunnen begrijpen.\u2022 Gedetailleerde informatie over de belangrijkste kenmerken die bijde besluitvorming in beschouwing worden genomen, de bron vandeze informatie en het belang ervan.Leg dit vast in de DPIA.Toelichting:De inzet van een algoritme is voor de betrokkene vaak onzichtbaar. De matewaarin mensen dergelijke processen begrijpen, verschilt per persoon. Voorsommigen kan het moeilijk zijn de complexe technieken te begrijpen.Bron: Artikel 5, lid 1, onder a AVG, Artikel 12-14 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.4", "norm_naam": "Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt (doelbinding)", "norm_tekst": "Norm: Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk\nomschreven en gerechtvaardigde doeleinden worden verzameld en mogen\nvervolgens niet verder op een met die doeleinden onverenigbare wijze\nworden verwerkt (doelbinding)*\nRisico: Er worden persoonsgegevens verwerkt zonder dat hiervoor een doel\nis bepaald. De verwerking van persoonsgegevens in het algoritme valt niet\nonder het doel waarvoor zij verzameld zijn of een hiermee verenigbaar doel.\nMaatregel:\nStel welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doelen\nvast voor de verwerking van persoonsgegevens. Check of de verwerking\npast binnen de wettelijke grondslag die geldt voor het uitvoeren van de\ntaak.\nPersoonsgegevens die reeds verzameld zijn mogen wel verder worden\nverwerkt voor andere doelen, maar alleen als die doelen verenigbaar zijn\nmet het oorspronkelijke verzameldoel. Om te bepalen of een nieuw doel\nverenigbaar is, moet een verenigbaarheidstoets worden uitgevoerd.\nLeg dit vast in de DPIA.\nToelichting:\nUitgangspunt is dat persoonsgegevens alleen mogen worden verwerkt als\nde verwerking noodzakelijk is met het oog op het bereiken van specifieke\ndoelen. Wanneer het gerechtvaardigd is om persoonsgegevens te\nverwerken, moet de verwerking ervan vervolgens netjes en verantwoord\ngebeuren. Ten slotte moet duidelijk zijn voor welke doelen\npersoonsgegevens worden verwerkt en hoe dat gebeurt.\nBron: Artikel 5, lid 1, onder b AVG en Overweging 50 AVG.\n", "norm_risico_namen": ["Norm: Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt (doelbinding) Risico: Er worden persoonsgegevens verwerkt zonder dat hiervoor een doelis bepaald. De verwerking van persoonsgegevens in het algoritme valt nietonder het doel waarvoor zij verzameld zijn of een hiermee verenigbaar doel."], "norm_risico_teksten": ["Norm: Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt (doelbinding) Risico: Er worden persoonsgegevens verwerkt zonder dat hiervoor een doelis bepaald. De verwerking van persoonsgegevens in het algoritme valt nietonder het doel waarvoor zij verzameld zijn of een hiermee verenigbaar doel.Maatregel:Stel welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doelenvast voor de verwerking van persoonsgegevens. Check of de verwerkingpast binnen de wettelijke grondslag die geldt voor het uitvoeren van detaak.Persoonsgegevens die reeds verzameld zijn mogen wel verder wordenverwerkt voor andere doelen, maar alleen als die doelen verenigbaar zijnmet het oorspronkelijke verzameldoel. Om te bepalen of een nieuw doelverenigbaar is, moet een verenigbaarheidstoets worden uitgevoerd.Leg dit vast in de DPIA.Toelichting:Uitgangspunt is dat persoonsgegevens alleen mogen worden verwerkt alsde verwerking noodzakelijk is met het oog op het bereiken van specifiekedoelen. Wanneer het gerechtvaardigd is om persoonsgegevens teverwerken, moet de verwerking ervan vervolgens netjes en verantwoordgebeuren. Ten slotte moet duidelijk zijn voor welke doelenpersoonsgegevens worden verwerkt en hoe dat gebeurt.Bron: Artikel 5, lid 1, onder b AVG en Overweging 50 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.5", "norm_naam": "Elke verwerking van persoonsgegevens moet gerechtvaardigd zijn", "norm_tekst": "Norm: Elke verwerking van persoonsgegevens moet gerechtvaardigd\nzijn.(*)\nRisico: De verwerking is niet gerechtvaardigd omdat het doel van de\nverwerking niet kan worden gebaseerd op \u00e9\u00e9n van de zes rechtsgrondslagen\ndie in de AVG worden gegeven.\nMaatregel:\nBepaal of de gegevensverwerking gerechtvaardigd is. De verwerking is\ngerechtvaardigd wanneer het doel van de verwerking kan worden gebaseerd\nop \u00e9\u00e9n van de zes rechtsgrondslagen die in de AVG worden gegeven. Kan\ndat niet, dan is het niet toegestaan persoonsgegevens te verwerken. De lijst\nvan rechtsgrondslagen is limitatief, er kunnen geen andere gronden worden\naangevoerd.*\nToelichting:\nIn de AVG staan de volgende 6 grondslagen voor het verwerken van\npersoonsgegevens:\n1. Toestemming van de persoon om wie het gaat.\n2. Het is noodzakelijk om persoonsgegevens te verwerken om een\novereenkomst uit te voeren.\n3. Het is noodzakelijk om persoonsgegevens te verwerken omdat dit\nwettelijk verplicht is.\n4. Het is noodzakelijk om gegevens te verwerken om vitale belangen\nte beschermen.\n5. Het is noodzakelijk om gegevens te verwerken om een taak van\nalgemeen belang of openbaar gezag uit te oefenen.\n6. Het is noodzakelijk om gegevens te verwerken om gerechtvaardigde\nbelang te behartigen\nWanneer er sprake is van een afhankelijkheidsrelatie, bijvoorbeeld in de\nrelatie overheid-burger, zal toestemming niet snel vrij zijn gegeven. Dit\nbetekent dat dergelijke situaties geen geldige toestemming kan worden\ngevraagd.\nVanwege het feit dat de wetgever de rechtsgrond bepaalt voor de\nverwerking van persoonsgegevens door overheidsinstanties, is de\nrechtsgrond \u2018gerechtvaardigd belang\u2019 niet van toepassing op verwerkingen\ndoor overheidsinstanties in het kader van de uitvoering van hun taken.\nVoor de verwerking van bijzondere categorie\u00ebn van persoonsgegevens en\npersoonsgegevens van strafrechtelijke aard gelden aanvullende\nvoorwaarden, deze bepalingen worden beschreven norm 3.4.10.\nLeg dit vast in de DPIA.\nBron: Artikel 6 AVG.", "norm_risico_namen": ["Norm: Elke verwerking van persoonsgegevens moet gerechtvaardigd zijn Risico: De verwerking is niet gerechtvaardigd omdat het doel van deverwerking niet kan worden gebaseerd op \u00e9\u00e9n van de zes rechtsgrondslagendie in de AVG worden gegeven."], "norm_risico_teksten": ["Norm: Elke verwerking van persoonsgegevens moet gerechtvaardigd zijn Risico: De verwerking is niet gerechtvaardigd omdat het doel van deverwerking niet kan worden gebaseerd op \u00e9\u00e9n van de zes rechtsgrondslagendie in de AVG worden gegeven.Maatregel:Bepaal of de gegevensverwerking gerechtvaardigd is. De verwerking isgerechtvaardigd wanneer het doel van de verwerking kan worden gebaseerdop \u00e9\u00e9n van de zes rechtsgrondslagen die in de AVG worden gegeven. Kandat niet, dan is het niet toegestaan persoonsgegevens te verwerken. De lijstvan rechtsgrondslagen is limitatief, er kunnen geen andere gronden wordenaangevoerd.*Toelichting:In de AVG staan de volgende 6 grondslagen voor het verwerken vanpersoonsgegevens:1. Toestemming van de persoon om wie het gaat.2. Het is noodzakelijk om persoonsgegevens te verwerken om eenovereenkomst uit te voeren.3. Het is noodzakelijk om persoonsgegevens te verwerken omdat ditwettelijk verplicht is.4. Het is noodzakelijk om gegevens te verwerken om vitale belangente beschermen.5. Het is noodzakelijk om gegevens te verwerken om een taak vanalgemeen belang of openbaar gezag uit te oefenen.6. Het is noodzakelijk om gegevens te verwerken om gerechtvaardigdebelang te behartigenWanneer er sprake is van een afhankelijkheidsrelatie, bijvoorbeeld in derelatie overheid-burger, zal toestemming niet snel vrij zijn gegeven. Ditbetekent dat dergelijke situaties geen geldige toestemming kan wordengevraagd.Vanwege het feit dat de wetgever de rechtsgrond bepaalt voor deverwerking van persoonsgegevens door overheidsinstanties, is derechtsgrond \u2018gerechtvaardigd belang\u2019 niet van toepassing op verwerkingendoor overheidsinstanties in het kader van de uitvoering van hun taken.Voor de verwerking van bijzondere categorie\u00ebn van persoonsgegevens enpersoonsgegevens van strafrechtelijke aard gelden aanvullendevoorwaarden, deze bepalingen worden beschreven norm 3.4.10.Leg dit vast in de DPIA.Bron: Artikel 6 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.6", "norm_naam": "De verwerkte persoonsgegevens zijn toereikend, ter zake dienend en beperkt tot het noodzakelijke (dataminimalisatie)", "norm_tekst": "Norm: De verwerkte persoonsgegevens zijn toereikend, ter zake dienend en\nbeperkt tot het noodzakelijke (dataminimalisatie). (*)\nRisico: De verwerkte persoonsgegevens zijn niet proportioneel en relevant\nin relatie tot het doel.\n\nMaatregel: Beoordeel welke persoonsgegevens voor het algoritme nodig zijn\nen hoe lang deze moeten worden bewaard. Gebruik waar mogelijk\ngeanonimiseerde of gepseudonimiseerde gegevens. (*)\nLeg dit vast in de DPIA\nBron: artikel 5 lid 1 onder c AVG.", "norm_risico_namen": ["Norm: De verwerkte persoonsgegevens zijn toereikend, ter zake dienend en beperkt tot het noodzakelijke (dataminimalisatie) Risico: De verwerkte persoonsgegevens zijn niet proportioneel en relevantin relatie tot het doel."], "norm_risico_teksten": ["Norm: De verwerkte persoonsgegevens zijn toereikend, ter zake dienend en beperkt tot het noodzakelijke (dataminimalisatie) Risico: De verwerkte persoonsgegevens zijn niet proportioneel en relevantin relatie tot het doel.Maatregel: Beoordeel welke persoonsgegevens voor het algoritme nodig zijnen hoe lang deze moeten worden bewaard. Gebruik waar mogelijkgeanonimiseerde of gepseudonimiseerde gegevens. (*)Leg dit vast in de DPIABron: artikel 5 lid 1 onder c AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.7", "norm_naam": "De gegevens zijn juist en zo nodig geactualiseerd", "norm_tekst": "Norm: De gegevens zijn juist en zo nodig geactualiseerd. (*)\nRisico: De kwaliteit en integriteit van data zijn niet voldoende geborgd.\nMaatregel: (verplicht)\nVerwerkingsverantwoordelijken moeten in alle stappen van het\nalgoritmeproces juistheid in het oog houden, in het bijzonder bij:\n\u2022 Het verzamelen van gegevens;\n\u2022 Het analyseren van gegevens;\n\u2022 Het opstellen van model; of\n\u2022 Het toepassen van een model om een besluit met betrekking tot de\npersoon te nemen\nLeg dit vast in de DPIA.\nToelichting: Als de gegevens die in het algoritme worden gebruikt onjuist\nzijn, zullen ook besluiten of profielen die daaruit voortkomen onjuist zijn.\nBesluiten zijn mogelijk genomen op basis van verouderde gegevens of de\nonjuiste interpretatie van externe gegevens. Zelfs wanneer ruwe gegevens\ncorrect worden opgeslagen, is de gegevensreeks mogelijk niet geheel\nrepresentatief of kunnen de analysegegevens ongemerkt vooroordelen\nbevatten.\nBron: artikel 5 lid 1 sub d AVG.", "norm_risico_namen": ["Norm: De gegevens zijn juist en zo nodig geactualiseerd Risico: De kwaliteit en integriteit van data zijn niet voldoende geborgd."], "norm_risico_teksten": ["Norm: De gegevens zijn juist en zo nodig geactualiseerd Risico: De kwaliteit en integriteit van data zijn niet voldoende geborgd.Maatregel: (verplicht)Verwerkingsverantwoordelijken moeten in alle stappen van hetalgoritmeproces juistheid in het oog houden, in het bijzonder bij:\u2022 Het verzamelen van gegevens;\u2022 Het analyseren van gegevens;\u2022 Het opstellen van model; of\u2022 Het toepassen van een model om een besluit met betrekking tot depersoon te nemenLeg dit vast in de DPIA.Toelichting: Als de gegevens die in het algoritme worden gebruikt onjuistzijn, zullen ook besluiten of profielen die daaruit voortkomen onjuist zijn.Besluiten zijn mogelijk genomen op basis van verouderde gegevens of deonjuiste interpretatie van externe gegevens. Zelfs wanneer ruwe gegevenscorrect worden opgeslagen, is de gegevensreeks mogelijk niet geheelrepresentatief of kunnen de analysegegevens ongemerkt vooroordelenbevatten.Bron: artikel 5 lid 1 sub d AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.8", "norm_naam": "Gegevens worden niet langer worden bewaard dan nodig (opslagbeperking)", "norm_tekst": "Norm: Gegevens worden niet langer worden bewaard dan nodig\n(opslagbeperking).*\nRisico: Persoonsgegevens worden langer bewaard dan nodig.\nMaatregel: De bewaartermijnen moeten aansluiten op de selectielijsten\n(Archiefwet). Zorg voor een vernietigingsprocedure, een document waaruit\nblijkt dat dit ingeregeld en/of uitgevoerd is.*\nLeg dit vast in DPIA.\nToelichting: Persoonsgegevens mogen niet langer bewaard worden dan\nnoodzakelijk voor het doel van de verwerking. Wanneer de gegevens niet\nlanger noodzakelijk zijn, dan moeten zij worden vernietigd of gewist.\nBron: Artikel 5, lid 1 AVG; Archiefwet.\n", "norm_risico_namen": ["Norm: Gegevens worden niet langer worden bewaard dan nodig (opslagbeperking) Risico: Persoonsgegevens worden langer bewaard dan nodig."], "norm_risico_teksten": ["Norm: Gegevens worden niet langer worden bewaard dan nodig (opslagbeperking) Risico: Persoonsgegevens worden langer bewaard dan nodig.Maatregel: De bewaartermijnen moeten aansluiten op de selectielijsten(Archiefwet). Zorg voor een vernietigingsprocedure, een document waaruitblijkt dat dit ingeregeld en/of uitgevoerd is.*Leg dit vast in DPIA.Toelichting: Persoonsgegevens mogen niet langer bewaard worden dannoodzakelijk voor het doel van de verwerking. Wanneer de gegevens nietlanger noodzakelijk zijn, dan moeten zij worden vernietigd of gewist.Bron: Artikel 5, lid 1 AVG; Archiefwet."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.9", "norm_naam": "Het algoritme verwerkt alleen bijzondere persoonsgegevens, strafrechtelijke gegevens of nationale identificatienummers (o.a. BSN) als deze op basis van een wettelijke uitzondering verwerkt mogen worden", "norm_tekst": "Norm: Het algoritme verwerkt alleen bijzondere persoonsgegevens,\nstrafrechtelijke gegevens of nationale identificatienummers (o.a. BSN) als\ndeze op basis van een wettelijke uitzondering verwerkt mogen worden.\nRisico: Verwerking van bijzondere persoonsgegevens (o.a. gegevens m.b.t.\nras of afkomst, religie, gezondheid of seksuele geaardheid), strafrechtelijke\ngegevens of nationale identificatienummers (o.a. BSN) is alleen toegestaan\nals hierop een wettelijke uitzondering van toepassing is.\nMaatregel:\nOp het verwerken van bijzondere categorie\u00ebn van persoonsgegevens rust\neen verwerkingsverbod. Hierop is echter wel een beperkt aantal\nuitzonderingen geformuleerd. Een deel van de uitzonderingen is geregeld in\nde AVG. De UAVG bevat daarnaast specifieke uitzonderingen per categorie.\n(*)\nDe verwerking van strafrechtelijke gegevens, is alleen toegestaan als dat\ngebeurt onder toezicht van de overheid, of als het specifiek bij wet is\ngeregeld.\nNationale identificatienummers mogen alleen worden gebruikt voor in de\nwet voorgeschreven doelen.\nLeg dit vast in de DPIA\nToelichting:\nBijzondere categorie\u00ebn van persoonsgegevens zijn gegevens die gezien hun\naard extra gevoelig zijn. Het gaat specifiek om: gegevens waaruit ras of\netnische afkomst blijkt, politieke opvattingen, religieuze of\nlevensbeschouwelijke overtuigingen, het lidmaatschap van een vakbond,\ngenetische gegevens, biometrische gegevens met het oog op de unieke\nidentificatie van een persoon, gegevens over gezondheid en gegevens met\nbetrekking tot iemands seksueel gedrag of seksuele gerichtheid.\nBron: Artikel 9, 10 en 87 AVG, Hoofdstuk 3 UAVG.", "norm_risico_namen": ["Norm: Het algoritme verwerkt alleen bijzondere persoonsgegevens, strafrechtelijke gegevens of nationale identificatienummers (o.a. BSN) als deze op basis van een wettelijke uitzondering verwerkt mogen worden Risico: Verwerking van bijzondere persoonsgegevens (o.a. gegevens m.b.t.ras of afkomst, religie, gezondheid of seksuele geaardheid), strafrechtelijkegegevens of nationale identificatienummers (o.a. BSN) is alleen toegestaanals hierop een wettelijke uitzondering van toepassing is."], "norm_risico_teksten": ["Norm: Het algoritme verwerkt alleen bijzondere persoonsgegevens, strafrechtelijke gegevens of nationale identificatienummers (o.a. BSN) als deze op basis van een wettelijke uitzondering verwerkt mogen worden Risico: Verwerking van bijzondere persoonsgegevens (o.a. gegevens m.b.t.ras of afkomst, religie, gezondheid of seksuele geaardheid), strafrechtelijkegegevens of nationale identificatienummers (o.a. BSN) is alleen toegestaanals hierop een wettelijke uitzondering van toepassing is.Maatregel:Op het verwerken van bijzondere categorie\u00ebn van persoonsgegevens rusteen verwerkingsverbod. Hierop is echter wel een beperkt aantaluitzonderingen geformuleerd. Een deel van de uitzonderingen is geregeld inde AVG. De UAVG bevat daarnaast specifieke uitzonderingen per categorie.(*)De verwerking van strafrechtelijke gegevens, is alleen toegestaan als datgebeurt onder toezicht van de overheid, of als het specifiek bij wet isgeregeld.Nationale identificatienummers mogen alleen worden gebruikt voor in dewet voorgeschreven doelen.Leg dit vast in de DPIAToelichting:Bijzondere categorie\u00ebn van persoonsgegevens zijn gegevens die gezien hunaard extra gevoelig zijn. Het gaat specifiek om: gegevens waaruit ras ofetnische afkomst blijkt, politieke opvattingen, religieuze oflevensbeschouwelijke overtuigingen, het lidmaatschap van een vakbond,genetische gegevens, biometrische gegevens met het oog op de uniekeidentificatie van een persoon, gegevens over gezondheid en gegevens metbetrekking tot iemands seksueel gedrag of seksuele gerichtheid.Bron: Artikel 9, 10 en 87 AVG, Hoofdstuk 3 UAVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.10", "norm_naam": "Betrokkenen kunnen een beroep doen op hun privacyrechten", "norm_tekst": "Norm: Betrokkenen kunnen een beroep doen op hun privacyrechten. (*)\nRisico: Bij het verwerken van persoonsgegevens in een algoritme is voor\ngebruikers niet duidelijk dat hier sprake van is waardoor ze geen beroep\nkunnen doen op hun privacyrechten.\nMaatregel: Geef aan hoe invulling wordt gegeven aan de rechten van\nbetrokkenen.(*) Stel een procedure vast waarmee o.a. aan verzoekers\ninformatie kan worden verstrekt over geautomatiseerde verwerking van\npersoonsgegevens en de onderliggende logica en het belang en de\nverwachte gevolgen van de verwerking.\nIndien de rechten van de betrokkene worden beperkt, bepaal dan op grond\nvan welke wettelijke uitzonderingen dat is toegestaan en leg dit vast.\nToelichting: Om een eerlijke verwerking van persoonsgegevens te\nwaarborgen geeft de AVG diverse rechten aan de betrokkene. De\n\nbetrokkene kan deze rechten uitoefenen tegen de\nverwerkingsverantwoordelijke.\nBron: Artikel 15-22 AVG.", "norm_risico_namen": ["Norm: Betrokkenen kunnen een beroep doen op hun privacyrechten Risico: Bij het verwerken van persoonsgegevens in een algoritme is voorgebruikers niet duidelijk dat hier sprake van is waardoor ze geen beroepkunnen doen op hun privacyrechten."], "norm_risico_teksten": ["Norm: Betrokkenen kunnen een beroep doen op hun privacyrechten Risico: Bij het verwerken van persoonsgegevens in een algoritme is voorgebruikers niet duidelijk dat hier sprake van is waardoor ze geen beroepkunnen doen op hun privacyrechten.Maatregel: Geef aan hoe invulling wordt gegeven aan de rechten vanbetrokkenen.(*) Stel een procedure vast waarmee o.a. aan verzoekersinformatie kan worden verstrekt over geautomatiseerde verwerking vanpersoonsgegevens en de onderliggende logica en het belang en deverwachte gevolgen van de verwerking.Indien de rechten van de betrokkene worden beperkt, bepaal dan op grondvan welke wettelijke uitzonderingen dat is toegestaan en leg dit vast.Toelichting: Om een eerlijke verwerking van persoonsgegevens tewaarborgen geeft de AVG diverse rechten aan de betrokkene. Debetrokkene kan deze rechten uitoefenen tegen deverwerkingsverantwoordelijke.Bron: Artikel 15-22 AVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.11", "norm_naam": "Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate tref", "norm_tekst": "Norm: Betrokkenen hebben het recht om niet onderworpen te worden aan\neen enkel op geautomatiseerde verwerking, waaronder proflering,\ngebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen\nanderszins in aanzienlijke mate tref. (*)\nRisico: Een betrokkene ondervindt aanmerkelijke gevolgen door een\ngeautomatiseerd besluit, zonder dat deze een beroep op menselijke\ntussenkomst kan doen.\nMaatregel:\nGa na of sprake is van een verboden vorm van geautomatiseerde\nverwerking van persoonsgegevens.\nDeze maatregelen moeten tenminste het volgende omvatten:\n\u2022 Het recht op menselijke tussenkomst;\n\u2022 Het recht voor de betrokkene om zijn standpunt kenbaar te maken;\nen\n\u2022 Het recht om het besluit aan te vechten.\nLeg dit vast in de DPIA.\nToelichting:\nBij uitsluitend geautomatiseerde individuele besluitvorming is er g\u00e9\u00e9n\nsprake van (noemenswaardige) menselijke tussenkomst.\nBron: artikel 22 AVG en artikel 40 UAVG.", "norm_risico_namen": ["Norm: Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate tref Risico: Een betrokkene ondervindt aanmerkelijke gevolgen door eengeautomatiseerd besluit, zonder dat deze een beroep op menselijketussenkomst kan doen."], "norm_risico_teksten": ["Norm: Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate tref Risico: Een betrokkene ondervindt aanmerkelijke gevolgen door eengeautomatiseerd besluit, zonder dat deze een beroep op menselijketussenkomst kan doen.Maatregel:Ga na of sprake is van een verboden vorm van geautomatiseerdeverwerking van persoonsgegevens.Deze maatregelen moeten tenminste het volgende omvatten:\u2022 Het recht op menselijke tussenkomst;\u2022 Het recht voor de betrokkene om zijn standpunt kenbaar te maken;en\u2022 Het recht om het besluit aan te vechten.Leg dit vast in de DPIA.Toelichting:Bij uitsluitend geautomatiseerde individuele besluitvorming is er g\u00e9\u00e9nsprake van (noemenswaardige) menselijke tussenkomst.Bron: artikel 22 AVG en artikel 40 UAVG."]}, {"waarde_nr": "3.4", "waarde_naam": "Privacy en datagovernance", "norm_nr": "3.4.12", "norm_naam": "Privacy en gegevensbescherming is meegenomen als eis bij het ontwerp van nieuwe systemen waarmee persoonsgegevens worden verwerkt. (\u2018privacy door ontwerp en standaardinstellingen/ Privacy by Design en Privacy by Default)", "norm_tekst": "Norm: Privacy en gegevensbescherming is meegenomen als eis bij het\nontwerp van nieuwe systemen waarmee persoonsgegevens worden\nverwerkt. (\u2018privacy door ontwerp en standaardinstellingen/ Privacy by\nDesign en Privacy by Default)\nRisico: Ontwerp en opzet van het algoritme zijn onvoldoende gericht op de\nbescherming van privacy.\nMaatregel:\nNeem technische en organisatorische maatregelen om invulling te geven\naan het uitgangspunt van privacy door ontwerp en door\nstandaardinstellingen. Bij het bepalen van de maatregelen moet rekening\nworden gehouden met de volgende elementen:\n\u2022 De stand van de techniek;\n\u2022 De uitvoeringskosten;\n\u2022 De aard, omvang, context en het doel van de verwerking;\n\u2022 De risico\u2019s voor de betrokkene.\nLeg dit vast in de DPIA.\n\nToelichting:\nPrivacy door ontwerp en door standaardinstellingen houdt in dat privacy en\ngegevensbescherming worden meegenomen als eisen bij de ontwikkeling\nhet ontwerp van nieuwe systemen waarmee persoonsgegevens worden\nverwerkt, waarbij een zo klein mogelijke inbreuk op de persoonlijke\nlevenssfeer wordt gemaakt, bijvoorbeeld door het toepassen van\npseudonimisering en het inbouwen van andere technische waarborgen.\nBron: Artikel 25 AVG.", "norm_risico_namen": ["Norm: Privacy en gegevensbescherming is meegenomen als eis bij het ontwerp van nieuwe systemen waarmee persoonsgegevens worden verwerkt. (\u2018privacy door ontwerp en standaardinstellingen/ Privacy by Design en Privacy by Default) Risico: Ontwerp en opzet van het algoritme zijn onvoldoende gericht op debescherming van privacy."], "norm_risico_teksten": ["Norm: Privacy en gegevensbescherming is meegenomen als eis bij het ontwerp van nieuwe systemen waarmee persoonsgegevens worden verwerkt. (\u2018privacy door ontwerp en standaardinstellingen/ Privacy by Design en Privacy by Default) Risico: Ontwerp en opzet van het algoritme zijn onvoldoende gericht op debescherming van privacy.Maatregel:Neem technische en organisatorische maatregelen om invulling te gevenaan het uitgangspunt van privacy door ontwerp en doorstandaardinstellingen. Bij het bepalen van de maatregelen moet rekeningworden gehouden met de volgende elementen:\u2022 De stand van de techniek;\u2022 De uitvoeringskosten;\u2022 De aard, omvang, context en het doel van de verwerking;\u2022 De risico\u2019s voor de betrokkene.Leg dit vast in de DPIA.Toelichting:Privacy door ontwerp en door standaardinstellingen houdt in dat privacy engegevensbescherming worden meegenomen als eisen bij de ontwikkelinghet ontwerp van nieuwe systemen waarmee persoonsgegevens wordenverwerkt, waarbij een zo klein mogelijke inbreuk op de persoonlijkelevenssfeer wordt gemaakt, bijvoorbeeld door het toepassen vanpseudonimisering en het inbouwen van andere technische waarborgen.Bron: Artikel 25 AVG."]}, {"waarde_nr": "3.5", "waarde_naam": "Transparantie", "norm_nr": "3.5.1", "norm_naam": "Besluitvorming dient transparant te zijn en moet zorgvuldig tot stand komen", "norm_tekst": "Norm: Besluitvorming dient transparant te zijn en moet zorgvuldig tot stand\nkomen.\nRisico: Gebrek aan transparantie, waardoor niet kan worden achterhaald of\naan een besluit een zorgvuldig proces vooraf is gegaan en of het voldoet\naan andere vereisten.\nMaatregel:\nAlgoritmen en modellen dienen transparant, betrouwbaar en controleerbaar\nte zijn, zodat achterhaald kan worden op basis van welke afwegingen een\nbesluit is genomen. (*)\nRicht een procedure in waardoor kan worden voldaan aan het recht op\ntoegang tot publieke informatie.\nToelichting:\nBij de voorbereiding van een besluit dient het bestuursorgaan alle relevante\ninformatie te verzamelen en de belangen van betrokkenen zorgvuldig af te\nwegen. Het besluit mag geen onredelijke of discriminerende gevolgen voor\nbetrokkenen hebben.\nBron: Artikel 3:2 en 3:46 Awb, artikel 1.1 en 2.5 Woo.", "norm_risico_namen": ["Norm: Besluitvorming dient transparant te zijn en moet zorgvuldig tot stand komen Risico: Gebrek aan transparantie, waardoor niet kan worden achterhaald ofaan een besluit een zorgvuldig proces vooraf is gegaan en of het voldoetaan andere vereisten."], "norm_risico_teksten": ["Norm: Besluitvorming dient transparant te zijn en moet zorgvuldig tot stand komen Risico: Gebrek aan transparantie, waardoor niet kan worden achterhaald ofaan een besluit een zorgvuldig proces vooraf is gegaan en of het voldoetaan andere vereisten.Maatregel:Algoritmen en modellen dienen transparant, betrouwbaar en controleerbaarte zijn, zodat achterhaald kan worden op basis van welke afwegingen eenbesluit is genomen. (*)Richt een procedure in waardoor kan worden voldaan aan het recht optoegang tot publieke informatie.Toelichting:Bij de voorbereiding van een besluit dient het bestuursorgaan alle relevanteinformatie te verzamelen en de belangen van betrokkenen zorgvuldig af tewegen. Het besluit mag geen onredelijke of discriminerende gevolgen voorbetrokkenen hebben.Bron: Artikel 3:2 en 3:46 Awb, artikel 1.1 en 2.5 Woo."]}, {"waarde_nr": "3.5", "waarde_naam": "Transparantie", "norm_nr": "3.5.2", "norm_naam": "Een besluit berust op een deugdelijke motivering", "norm_tekst": "Norm: Een besluit berust op een deugdelijke motivering.*\nRisico: Het is niet duidelijk dat het besluit (gedeeltelijk) op een algoritme is\ngebaseerd.\nMaatregel: Richt een procedure in waarmee bij een besluit dat is gebaseerd\nop een algoritme uit eigen beweging gemaakte keuzes en gebruikte\ngegevens en aannames aan de betrokkene inzichtelijk worden gemaakt of\nworden gedocumenteerd. *\nEen bestuursorgaan moet inzichtelijk maken:\n\n1. dat een besluit tot stand is gekomen met behulp van een algoritme;\n2. van welke feiten het is uitgegaan en welke gegevens van de burger\ngebruikt c.q. verwerkt zijn;\n3. welke relevante belangen tegen elkaar zijn afgewogen en hoe die\nafweging is verlopen (bijvoorbeeld het gewicht dat wordt toegekend aan elk\nafgewogen kenmerk; welke analytische technieken gebruikt zijn; welke\nspecifieke voorspellende data; wat de belangrijkste policy-keuzes waren;\neen uitleg van het voorspellende algoritme);\n4. hoe het algoritme werkt (niet de techniek, maar hoe de uitkomsten van\nhet algoritme tot stand komen).\nOfwel, welke keuzes en aannames zijn gemaakt en welke invoergegevens\nzijn gebruikt.\nToelichting: Transparantie vormt de kern van maatregelen om grip te\nkrijgen op algoritmische besluitvorming. Bij het bepalen van deze\ntransparantie kan worden aangesloten bij het motiverings- en het\nzorgvuldigheidsbeginsel. Een besluit dat is gebaseerd op een algoritme dient\nte berusten op een deugdelijke motivering. De motivering wordt vermeld bij\nde bekendmaking van het besluit.\nBron: Artikel 3:46 - 3:50 Awb, Jurisprudentie over AERIUS (ABRvS 18 juli\n2018, ECLI:NL:RVS:2018:2454), Hof van Justitie C-274/18.", "norm_risico_namen": ["Norm: Een besluit berust op een deugdelijke motivering Risico: Het is niet duidelijk dat het besluit (gedeeltelijk) op een algoritme isgebaseerd."], "norm_risico_teksten": ["Norm: Een besluit berust op een deugdelijke motivering Risico: Het is niet duidelijk dat het besluit (gedeeltelijk) op een algoritme isgebaseerd.Maatregel: Richt een procedure in waarmee bij een besluit dat is gebaseerdop een algoritme uit eigen beweging gemaakte keuzes en gebruiktegegevens en aannames aan de betrokkene inzichtelijk worden gemaakt ofworden gedocumenteerd. *Een bestuursorgaan moet inzichtelijk maken:1. dat een besluit tot stand is gekomen met behulp van een algoritme;2. van welke feiten het is uitgegaan en welke gegevens van de burgergebruikt c.q. verwerkt zijn;3. welke relevante belangen tegen elkaar zijn afgewogen en hoe dieafweging is verlopen (bijvoorbeeld het gewicht dat wordt toegekend aan elkafgewogen kenmerk; welke analytische technieken gebruikt zijn; welkespecifieke voorspellende data; wat de belangrijkste policy-keuzes waren;een uitleg van het voorspellende algoritme);4. hoe het algoritme werkt (niet de techniek, maar hoe de uitkomsten vanhet algoritme tot stand komen).Ofwel, welke keuzes en aannames zijn gemaakt en welke invoergegevenszijn gebruikt.Toelichting: Transparantie vormt de kern van maatregelen om grip tekrijgen op algoritmische besluitvorming. Bij het bepalen van dezetransparantie kan worden aangesloten bij het motiverings- en hetzorgvuldigheidsbeginsel. Een besluit dat is gebaseerd op een algoritme dientte berusten op een deugdelijke motivering. De motivering wordt vermeld bijde bekendmaking van het besluit.Bron: Artikel 3:46 - 3:50 Awb, Jurisprudentie over AERIUS (ABRvS 18 juli2018, ECLI:NL:RVS:2018:2454), Hof van Justitie C-274/18."]}, {"waarde_nr": "3.5", "waarde_naam": "Transparantie", "norm_nr": "3.5.3", "norm_naam": "De besluitvorming door het algoritme is traceerbaar", "norm_tekst": "Norm: De besluitvorming door het algoritme is traceerbaar.\nRisico: Het is niet goed na te gaan op welke manier het algoritme tot het\nbesluit is gekomen.\nMaatregel:\nNeem maatregelen om de traceerbaarheid in de besluitvorming te\nwaarborgen. Daarbij kan het gaan om de documentatie van:\n\u2022 Het ontwerp en de ontwikkeling van door het algoritme gebruikte\nmethoden.\n\u2022 Het testen en valideren van door het algoritme gebruikte methoden\n\u2022 Resultaten van het algoritme\n\u2022 Onderzoek in hoeverre de door het algoritme genomen beslissingen\nen dus het resultaat kunnen worden begrepen.\n\u2022 Zorg ervoor dat er voor alle eindgebruikers die een verklaring\nwensen, een voor hen begrijpelijke verklaring kan worden gemaakt\n\u2022 Onderzoek in hoeverre de beslissingen van het systeem van invloed\nzijn op het besluitvormingsproces binnen de organisatie.\n\u2022 Onderzoek en toon aan welk model het eenvoudigst zou zijn voor\nde betreffende toepassing.\n\u2022 Controleer of trainings- en testgegevens kunnen worden\ngeanalyseerd. Kunnen deze in de loop van de tijd worden veranderd\nen bijgewerkt?\n\u2022 Onderzoek of na de training en ontwikkeling van het model er\nmogelijkheden zijn om de interpreteerbaarheid te beoordelen en of\ner toegang is tot de interne werkstroom van het model.\nToelichting: Indien de totstandkoming van een besluit dat met behulp van\neen algoritme is genomen niet traceerbaar is, kan het algoritme niet worden\ngecontroleerd.\n\nBron: EC/AI HLEG April 2019 - Hoofdstuk II.1.4.", "norm_risico_namen": ["Norm: De besluitvorming door het algoritme is traceerbaar Risico: Het is niet goed na te gaan op welke manier het algoritme tot hetbesluit is gekomen."], "norm_risico_teksten": ["Norm: De besluitvorming door het algoritme is traceerbaar Risico: Het is niet goed na te gaan op welke manier het algoritme tot hetbesluit is gekomen.Maatregel:Neem maatregelen om de traceerbaarheid in de besluitvorming tewaarborgen. Daarbij kan het gaan om de documentatie van:\u2022 Het ontwerp en de ontwikkeling van door het algoritme gebruiktemethoden.\u2022 Het testen en valideren van door het algoritme gebruikte methoden\u2022 Resultaten van het algoritme\u2022 Onderzoek in hoeverre de door het algoritme genomen beslissingenen dus het resultaat kunnen worden begrepen.\u2022 Zorg ervoor dat er voor alle eindgebruikers die een verklaringwensen, een voor hen begrijpelijke verklaring kan worden gemaakt\u2022 Onderzoek in hoeverre de beslissingen van het systeem van invloedzijn op het besluitvormingsproces binnen de organisatie.\u2022 Onderzoek en toon aan welk model het eenvoudigst zou zijn voorde betreffende toepassing.\u2022 Controleer of trainings- en testgegevens kunnen wordengeanalyseerd. Kunnen deze in de loop van de tijd worden veranderden bijgewerkt?\u2022 Onderzoek of na de training en ontwikkeling van het model ermogelijkheden zijn om de interpreteerbaarheid te beoordelen en ofer toegang is tot de interne werkstroom van het model.Toelichting: Indien de totstandkoming van een besluit dat met behulp vaneen algoritme is genomen niet traceerbaar is, kan het algoritme niet wordengecontroleerd.Bron: EC/AI HLEG April 2019 - Hoofdstuk II.1.4."]}, {"waarde_nr": "3.5", "waarde_naam": "Transparantie", "norm_nr": "3.5.4", "norm_naam": "De inzet en werking van het algoritme is gepubliceerd in een register en inzichtelijk voor belanghebbenden", "norm_tekst": "Norm: De inzet en werking van het algoritme is gepubliceerd in een register\nen inzichtelijk voor belanghebbenden.\nRisico: Ontbreken transparantie voor burgers/bedrijven/stakeholders\n(belanghebbenden)\nMaatregel:\nOpname van het algoritme in het centrale algoritmeregister of op sites als\ngithub.com, inclusief beschrijving van werking, gebruikte data en/of\nbeschrijving daarvan. Belanghebbenden worden zo op een begrijpelijke\nmanier ge\u00efnformeerd over onderliggende logica van het algoritme, alsmede\nhet belang en de verwachte gevolgen van die verwerking voor de\nbetrokkene.\nToelichting:\nDoel van publicatie van informatie over het algoritme is het bieden van\ntransparantie naar betrokkenen. Het zorgt ervoor dat het voor de vooraf\nbepaalde personen/doelgroepen duidelijk is dat zij met een algoritme te\nmaken hebben, welke consequenties dat heeft en welke beperkingen het\nalgoritme kent. De gewenste mate van transparantie (technische\ntransparantie vs. uitlegbaarheid) is weloverwogen; het hangt af van 1) de\nimpact van het algoritme op de beslissing, uitkomst en burger, (2) de mate\nvan autonomie bij de besluitvorming en (3) het type en de complexiteit van\nhet algoritme. De informatie dient voldoende begrijpelijk te zijn voor de\ndoelgroep(en).\nBron: EC/AI HLEG April 2019 - Hoofdstuk II.1.4.", "norm_risico_namen": ["Norm: De inzet en werking van het algoritme is gepubliceerd in een register en inzichtelijk voor belanghebbenden Risico: Ontbreken transparantie voor burgers/bedrijven/stakeholders(belanghebbenden)"], "norm_risico_teksten": ["Norm: De inzet en werking van het algoritme is gepubliceerd in een register en inzichtelijk voor belanghebbenden Risico: Ontbreken transparantie voor burgers/bedrijven/stakeholders(belanghebbenden)Maatregel:Opname van het algoritme in het centrale algoritmeregister of op sites alsgithub.com, inclusief beschrijving van werking, gebruikte data en/ofbeschrijving daarvan. Belanghebbenden worden zo op een begrijpelijkemanier ge\u00efnformeerd over onderliggende logica van het algoritme, alsmedehet belang en de verwachte gevolgen van die verwerking voor debetrokkene.Toelichting:Doel van publicatie van informatie over het algoritme is het bieden vantransparantie naar betrokkenen. Het zorgt ervoor dat het voor de voorafbepaalde personen/doelgroepen duidelijk is dat zij met een algoritme temaken hebben, welke consequenties dat heeft en welke beperkingen hetalgoritme kent. De gewenste mate van transparantie (technischetransparantie vs. uitlegbaarheid) is weloverwogen; het hangt af van 1) deimpact van het algoritme op de beslissing, uitkomst en burger, (2) de matevan autonomie bij de besluitvorming en (3) het type en de complexiteit vanhet algoritme. De informatie dient voldoende begrijpelijk te zijn voor dedoelgroep(en).Bron: EC/AI HLEG April 2019 - Hoofdstuk II.1.4."]}, {"waarde_nr": "3.6", "waarde_naam": "Diversiteit, non -discriminatie en rechtvaardigheid", "norm_nr": "3.6.1", "norm_naam": "Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan", "norm_tekst": "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden.\nDiscriminatie wegens godsdienst, levensovertuiging, politieke gezindheid,\nras, geslacht of op welke grond dan ook, is niet toegestaan. (*)\n1 Risico:\nToepassing van het model leidt tot discriminatie op basis van beschermde\npersoonskenmerken.\n\nMaatregel:\nStel vast of bij het doel, design of de uitkomst van het algoritme sprake is\nvan (direct of indirect) onderscheid. Maak bij de uitkomst ook gebruik van\ncontrolevariabelen (bijvoorbeeld nationaliteit/ras). Bepaal of er een\nwettelijke uitzondering of een objectieve rechtvaardiging is. Maak de\nconsequentie expliciet en leg deze op het juiste niveau vast. Neem indien\nnodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)\nstopzetten van het algoritme.\nToelichting:\nEr is sprake van een objectieve rechtvaardiging als sprake is van een\nlegitiem doel en het middel dat wordt gebruikt om het doel te bereiken is\npassend, noodzakelijk en evenredig. Om te bepalen of een algoritme\nverboden onderscheid maakt, moet worden bekeken of door het algoritme\nsprake is van een ongelijke behandeling van een persoon of groep personen\nin verhouding tot anderen in een vergelijkbare situatie.\nBron: Grondwet Art. 1 EVRM Art. 1 en 14 Algemene wet gelijke behandeling,\nProtocol 12.\nRisico:\nAndere data dan beschermde persoonskenmerken leiden tot discriminatie\nin de uitkomsten.\nMaatregelen:\n\u2022 Zorg voor gelijke mate van vertegenwoordiging relevante groepen.\nSelecteer een afgebakende toepassing om het systeem te testen;\nzorg dat deze afgebakende toepassing representatief is voor het\ngehele domein waarop het AI-systeem later wordt ingezet. Maak de\nconsequenties expliciet en leg deze op het juiste niveau vast. Neem\nindien nodig tegenmaatregelen. Een ultieme tegenmaatregel kan\nzijn het (tijdelijk) stopzetten van het algoritme.\n\u2022 Documenteer de mate van afhankelijkheid van historische data.\nWeeg af of de geconstateerde afhankelijkheid wenselijk is en of deze\nop discriminatie duidt. Maak de consequenties expliciet en leg deze\nop het juiste niveau vast. Neem indien nodig tegenmaatregelen. Een\nultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het\nalgoritme.\nToelichting:\n\u2022 Onvoldoende representativiteit in de trainingsdata kan leiden tot\nongelijke uitkomsten.\n\u2022 Onvoldoende representativiteit in de trainingsdata kan leiden tot\nongelijke uitkomsten. Kan bij voorspellende algoritmen ook leiden\ntot ongewenste feedbackloops. (Gebruik van data van bijvoorbeeld\nvroegere surveillance en criminaliteitscijfers in nieuwe algoritmen\nalgoritmen tot link aan wijken, personen met een\n\nimmigratieachtergrond. Indien het geval, is dit niet representatief\nen neutraal)\nBronnen:\nGrondwet Art. 1.\nEVRM Art. 1 en 14 Algemene wet gelijke behandeling, Protocol 12.\nArtikel 9 AVG.\nArtikel 14 EVRM jo. 21 HvEU jo. 1 GW.\n3 Risico: Het gebruik van proxy variabelen leidt tot indirecte discriminatie.\nMaatregel:\nIdentificeer bij een onrechtmatigheid in de uitkomst van het algoritme\nogenschijnlijk neutrale data (proxies). Maak de consequenties expliciet en\nleg deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen.\nEen ultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het\nalgoritme.\nToelichting:\nOgenschijnlijk neutrale data die op het eerste gezicht bijvoorbeeld geen\nenkele link hebben met afkomst of nationaliteit kunnen leiden tot indirect\nonderscheid op grond van ras of nationaliteit. Voorbeelden zijn postcode,\nhoogte van inkomen, hoogte van inkomensafhankelijke toeslagen,\nkinderopvang door een gastouderbureau met een \u2018homogeen\u2019\nklantenbestand, een familielid in het buitenland, kenteken en\nlaaggeletterdheid.\nBron: Artikel 1 lid 1 sub c Awgb.\n4 Risico: Bias in het algoritme leidt tot discriminatie.\nMaatregelen:\n1. Beoordeel of de geconstateerde bias wenselijk is en of deze op\ndiscriminatie duidt. Maak de consequenties expliciet en leg deze op het\njuiste niveau vast. Neem indien nodig tegenmaatregelen. Een ultieme\ntegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme. Van\nbelang bij de gemeten bias die duidt op discriminatie is het kijken vanuit\nwetgeving \u00e9n wenselijkheid.\n2. Documenteer in de functionele eisen de definitie van acceptabele bias. In\nde documentatie waarin deze eisen tot meetbare prestatiecriteria zijn\nuitgewerkt is te vinden welke fairness metrics hierbij horen. Maak de\nconsequenties expliciet. Eerst moet duidelijk worden wat eerlijk is voor het\nproces. Dan kunnen fairness metrics worden opgesteld om eerlijkheid te\nmeten.\n3. Documenteer in de functionele eisen de methoden van voorkomen,\ndetecteren en corrigeren van bias. Maak de consequenties expliciet.\nDocumentatie van de aanpak van bias bevordert de controleerbaarheid.\n\n4. Documenteer in de functionele eisen de doelstelling voor en definitie van\nde verschillende groepen en gewenste prestatie van het model voor deze\ngroepen. Maak de consequenties expliciet en bespreek dit in het ethisch\ngesprek. De keuze voor een gewenste prestatie per groep is een ethische\nafweging.\n5. Documenteer de mate van bias in de (trainings)data, dataverzameling en\nhet model. Maak de consequenties expliciet en leg deze op het juiste niveau\nvast. Neem indien nodig tegenmaatregelen. Een ultieme tegenmaatregel\nkan zijn het (tijdelijk) stopzetten van het algoritme. Bias in de trainingsdata,\nregels in het model en de beslissing van de eindgebruiker kunnen leiden tot\nbias. Bias in de inputdata kan doorwerken tot bias in de uitkomst.\n6. Beoordeel tijdens de ontwikkeling van het model of een verschil bestaat\ntussen prestatie van het model voor verschillende subgroepen. Maak de\nconsequenties expliciet en leg deze op het juiste niveau vast. Neem indien\nnodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)\nstopzetten van het algoritme. Een model kan gemiddeld goed presteren,\nmaar kan voor bepaalde subgroepen die minder in de testset aanwezig\nwaren verkeerde uitkomsten geven.\n7. Beoordeel of de uitkomstbias van de productiedata voor de verschillende\nsubgroepen voldoet aan de productiecriteria. Doe dit ook met een testset\ngedurende het ontwikkelproces. Maak de consequenties expliciet en leg\ndeze op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Een\nultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme.\nTijdens de ontwikkeling van het model kunnen methoden om bias te\ncorrigeren helpen om aan de prestatiecriteria te voldoen. Testresultaten op\nde uitkomstbias tijdens het ontwikkelen zijn ook wenselijk. Merk op dat voor\nhet meten van uitkomstbias alleen de inputdata en uitkomst van het model\nnodig is. Uitkomstbias kan zonder gelabelde dataset gemeten worden.\nToelichting:\nIn de hierboven beschreven maatregelen is te zien dat veel vormen van bias\nbestaan die elk op hun eigen manier tegengegaan kunnen worden. Vandaar\ndat de toelichting hierop direct achter de maatregel is geplaatst.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1, 1.5.", "norm_risico_namen": ["Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Toepassing van het model leidt tot discriminatie op basis van beschermdepersoonskenmerken.", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Andere data dan beschermde persoonskenmerken leiden tot discriminatiein de uitkomsten.", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Het gebruik van proxy variabelen leidt tot indirecte discriminatie.", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Bias in het algoritme leidt tot discriminatie."], "norm_risico_teksten": ["Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Toepassing van het model leidt tot discriminatie op basis van beschermdepersoonskenmerken.Maatregel:Stel vast of bij het doel, design of de uitkomst van het algoritme sprake isvan (direct of indirect) onderscheid. Maak bij de uitkomst ook gebruik vancontrolevariabelen (bijvoorbeeld nationaliteit/ras). Bepaal of er eenwettelijke uitzondering of een objectieve rechtvaardiging is. Maak deconsequentie expliciet en leg deze op het juiste niveau vast. Neem indiennodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)stopzetten van het algoritme.Toelichting:Er is sprake van een objectieve rechtvaardiging als sprake is van eenlegitiem doel en het middel dat wordt gebruikt om het doel te bereiken ispassend, noodzakelijk en evenredig. Om te bepalen of een algoritmeverboden onderscheid maakt, moet worden bekeken of door het algoritmesprake is van een ongelijke behandeling van een persoon of groep personenin verhouding tot anderen in een vergelijkbare situatie.Bron: Grondwet Art. 1 EVRM Art. 1 en 14 Algemene wet gelijke behandeling,Protocol", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Andere data dan beschermde persoonskenmerken leiden tot discriminatiein de uitkomsten.Maatregelen:\u2022 Zorg voor gelijke mate van vertegenwoordiging relevante groepen.Selecteer een afgebakende toepassing om het systeem te testen;zorg dat deze afgebakende toepassing representatief is voor hetgehele domein waarop het AI-systeem later wordt ingezet. Maak deconsequenties expliciet en leg deze op het juiste niveau vast. Neemindien nodig tegenmaatregelen. Een ultieme tegenmaatregel kanzijn het (tijdelijk) stopzetten van het algoritme.\u2022 Documenteer de mate van afhankelijkheid van historische data.Weeg af of de geconstateerde afhankelijkheid wenselijk is en of dezeop discriminatie duidt. Maak de consequenties expliciet en leg dezeop het juiste niveau vast. Neem indien nodig tegenmaatregelen. Eenultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van hetalgoritme.Toelichting:\u2022 Onvoldoende representativiteit in de trainingsdata kan leiden totongelijke uitkomsten.\u2022 Onvoldoende representativiteit in de trainingsdata kan leiden totongelijke uitkomsten. Kan bij voorspellende algoritmen ook leidentot ongewenste feedbackloops. (Gebruik van data van bijvoorbeeldvroegere surveillance en criminaliteitscijfers in nieuwe algoritmenalgoritmen tot link aan wijken, personen met eenimmigratieachtergrond. Indien het geval, is dit niet representatiefen neutraal)Bronnen:Grondwet Art. 1.EVRM Art. 1 en 14 Algemene wet gelijke behandeling, Protocol 12.Artikel 9 AVG.Artikel 14 EVRM jo. 21 HvEU jo. 1 GW.", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Het gebruik van proxy variabelen leidt tot indirecte discriminatie.Maatregel:Identificeer bij een onrechtmatigheid in de uitkomst van het algoritmeogenschijnlijk neutrale data (proxies). Maak de consequenties expliciet enleg deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen.Een ultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van hetalgoritme.Toelichting:Ogenschijnlijk neutrale data die op het eerste gezicht bijvoorbeeld geenenkele link hebben met afkomst of nationaliteit kunnen leiden tot indirectonderscheid op grond van ras of nationaliteit. Voorbeelden zijn postcode,hoogte van inkomen, hoogte van inkomensafhankelijke toeslagen,kinderopvang door een gastouderbureau met een \u2018homogeen\u2019klantenbestand, een familielid in het buitenland, kenteken enlaaggeletterdheid.Bron: Artikel 1 lid 1 sub c Awgb.", "Norm: Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Risico: Bias in het algoritme leidt tot discriminatie.Maatregelen:1. Beoordeel of de geconstateerde bias wenselijk is en of deze opdiscriminatie duidt. Maak de consequenties expliciet en leg deze op hetjuiste niveau vast. Neem indien nodig tegenmaatregelen. Een ultiemetegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme. Vanbelang bij de gemeten bias die duidt op discriminatie is het kijken vanuitwetgeving \u00e9n wenselijkheid.2. Documenteer in de functionele eisen de definitie van acceptabele bias. Inde documentatie waarin deze eisen tot meetbare prestatiecriteria zijnuitgewerkt is te vinden welke fairness metrics hierbij horen. Maak deconsequenties expliciet. Eerst moet duidelijk worden wat eerlijk is voor hetproces. Dan kunnen fairness metrics worden opgesteld om eerlijkheid temeten.3. Documenteer in de functionele eisen de methoden van voorkomen,detecteren en corrigeren van bias. Maak de consequenties expliciet.Documentatie van de aanpak van bias bevordert de controleerbaarheid.4. Documenteer in de functionele eisen de doelstelling voor en definitie vande verschillende groepen en gewenste prestatie van het model voor dezegroepen. Maak de consequenties expliciet en bespreek dit in het ethischgesprek. De keuze voor een gewenste prestatie per groep is een ethischeafweging.5. Documenteer de mate van bias in de (trainings)data, dataverzameling enhet model. Maak de consequenties expliciet en leg deze op het juiste niveauvast. Neem indien nodig tegenmaatregelen. Een ultieme tegenmaatregelkan zijn het (tijdelijk) stopzetten van het algoritme. Bias in de trainingsdata,regels in het model en de beslissing van de eindgebruiker kunnen leiden totbias. Bias in de inputdata kan doorwerken tot bias in de uitkomst.6. Beoordeel tijdens de ontwikkeling van het model of een verschil bestaattussen prestatie van het model voor verschillende subgroepen. Maak deconsequenties expliciet en leg deze op het juiste niveau vast. Neem indiennodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het (tijdelijk)stopzetten van het algoritme. Een model kan gemiddeld goed presteren,maar kan voor bepaalde subgroepen die minder in de testset aanwezigwaren verkeerde uitkomsten geven.7. Beoordeel of de uitkomstbias van de productiedata voor de verschillendesubgroepen voldoet aan de productiecriteria. Doe dit ook met een testsetgedurende het ontwikkelproces. Maak de consequenties expliciet en legdeze op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Eenultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme.Tijdens de ontwikkeling van het model kunnen methoden om bias tecorrigeren helpen om aan de prestatiecriteria te voldoen. Testresultaten opde uitkomstbias tijdens het ontwikkelen zijn ook wenselijk. Merk op dat voorhet meten van uitkomstbias alleen de inputdata en uitkomst van het modelnodig is. Uitkomstbias kan zonder gelabelde dataset gemeten worden.Toelichting:In de hierboven beschreven maatregelen is te zien dat veel vormen van biasbestaan die elk op hun eigen manier tegengegaan kunnen worden. Vandaardat de toelichting hierop direct achter de maatregel is geplaatst.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1, 1.5."]}, {"waarde_nr": "3.7", "waarde_naam": "Milieu en maatschappelijke waarden", "norm_nr": "3.7.1", "norm_naam": "Bewerkstellig duurzaamheid; ook in de ontwikkeling van algoritmen", "norm_tekst": "Norm: Bewerkstellig duurzaamheid; ook in de ontwikkeling van algoritmen.\nRisico: De impact van het model op het milieu is disproportioneel hoog.\n\nAanbeveling: Inventariseer de impact op het milieu en neem deze mee bij\nde modelkeuze en ontwikkeling. Maak de consequenties expliciet en leg\ndeze op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Een\nultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme.\nToelichting: Het trainen van een neuraal netwerk kost bijvoorbeeld meer\nenergie dan een beslisboom. Er is meegenomen of de hoeveelheid gebruikte\nenergie proportioneel is voor het doel van het algoritme. Daarnaast is\nnagedacht hoe de milieu-impact bij de ontwikkeling zo laag mogelijk kan\nworden gehouden. Parameters worden bijvoorbeeld tijdens het trainen niet\nvia trial and error bepaald als deze ook afgeleid kunnen worden.\nBron: SDG 11/ EC/AI HLEG April 2019 hoofdstuk II 1.6.", "norm_risico_namen": ["Norm: Bewerkstellig duurzaamheid; ook in de ontwikkeling van algoritmen Risico: De impact van het model op het milieu is disproportioneel hoog."], "norm_risico_teksten": ["Norm: Bewerkstellig duurzaamheid; ook in de ontwikkeling van algoritmen Risico: De impact van het model op het milieu is disproportioneel hoog.Aanbeveling: Inventariseer de impact op het milieu en neem deze mee bijde modelkeuze en ontwikkeling. Maak de consequenties expliciet en legdeze op het juiste niveau vast. Neem indien nodig tegenmaatregelen. Eenultieme tegenmaatregel kan zijn het (tijdelijk) stopzetten van het algoritme.Toelichting: Het trainen van een neuraal netwerk kost bijvoorbeeld meerenergie dan een beslisboom. Er is meegenomen of de hoeveelheid gebruikteenergie proportioneel is voor het doel van het algoritme. Daarnaast isnagedacht hoe de milieu-impact bij de ontwikkeling zo laag mogelijk kanworden gehouden. Parameters worden bijvoorbeeld tijdens het trainen nietvia trial and error bepaald als deze ook afgeleid kunnen worden.Bron: SDG 11/ EC/AI HLEG April 2019 hoofdstuk II 1.6."]}, {"waarde_nr": "3.8", "waarde_naam": "Verantwoording", "norm_nr": "3.8.1", "norm_naam": "Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel)", "norm_tekst": "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen\n(zorgvuldigheidsbeginsel).\n1 Risico: Risico: Zonder eenduidigheid over het doel is geen sturing op en\nverantwoording over het algoritme mogelijk en is er een groter risico op\nfouten en/of verschillen in interpretatie.\nMaatregel: Het doel en eventuele subdoelen van het algoritme moeten zo\nspecifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.\nMaak hiervoor gebruik van een multidisciplinaire aanpak en betrek hierbij\nmeerdere afdelingen en stakeholders. Maak de consequenties expliciet en\nleg deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen.\nEen ultieme tegenmaatregel kan zijn het niet inzetten van het algoritme.\nToelichting: Het doel van het algoritme moet helder zijn gedefinieerd, ook\nin relatie tot het maatschappelijke resultaat (outcome), en wordt gedeeld\ndoor de eigenaar, ontwikkelaar en gebruiker van het algoritme. Een bewuste\nafweging of het algoritme het juiste middel is om het probleem op\ndoelmatige en doeltreffende wijze op te lossen is gemaakt en vastgelegd.\nDe publieke waarden die met de inzet van algoritmen worden ingegeven,\nzoals gelijkwaardigheid en veiligheid, maar ook grondrechten die worden\ngeraakt, zijn ge\u00efnventariseerd en gewogen. Ook de doeltreffendheid,\nsubsidiariteit en proportionaliteit van het in te zetten algoritme zijn\nafgewogen.\nBron: Art. 3.2 Awb (bij besluiten)\n\nEC/AI HLEG April 2019 - Hoofdstuk II. 1.1 en 1.7.\n2 Risico: De impact van het algoritme is niet inzichtelijk, waardoor niet\nhelder is welke maatregelen moeten worden getroffen om ongewenste\neffecten (zoals bias en discriminatie) te voorkomen.\nMaatregel: Onderzoek (aan de hand van een mensenrechtentoets) welke\ngroepen kwetsbaar zijn voor een fout van het algoritme en welke impact\ndat heeft op deze groepen. Het betreft de \u2018menselijke maat\u2019 bij het nemen\nvan beslissingen op basis van de output van het algoritme. Maak de\nconsequenties expliciet en leg deze op het juiste niveau vast. Neem indien\nnodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het niet\ninzetten van het algoritme.\nToelichting: Het gaat om zowel de impact op personen of doelgroepen, als\nde bredere impact op de samenleving (vanuit sociaal, democratisch en\nmilieu/ecologisch perspectief).\nBron: Art. 3.2 Awb (bij besluiten)\nEC/AI HLEG April 2019 - Hoofdstuk I. 1.1 & Hoofdstuk II. 1.6.\n3 Risico: Zonder actueel beeld van risico's kan er geen goede afweging\nworden gemaakt of de voordelen van de toepassing van het algoritme\nopwegen tegen de nadelen. Risico's worden niet (tijdig) vastgesteld en\nadequaat geadresseerd en behandeld.\nMaatregel: Zorg ervoor dat op vastgelegde (periodieke) momenten een\nafweging plaats vindt van de risico\u2019s over het gebruik van het algoritme.\nAlle stappen van risicomanagement zijn uitgevoerd en op het juiste niveau\nin de organisatie behandeld, waaronder het identificeren, analyseren,\nevalueren (t.a.v. risk appetite), behandelen (risicoreactie, o.a.\nmaatregelen), monitoren & beoordelen en communiceren & rapporteren van\nrisico's. Maak de consequenties expliciet en leg deze op het juiste niveau\nvast. Neem indien nodig tegenmaatregelen. Een ultieme tegenmaatregel\nkan zijn het niet inzetten of (tijdelijk) stopzetten van het algoritme.\nToelichting: Het gaat hier om het feit dat er over risico's wordt nagedacht.\nDe organisatie moet beschikken over een ingericht en gedocumenteerd\nproces voor risicobeheersing.\nBron: Art. 3.2 Awb (bij besluiten)\nCOBIT EDM03 / APO12.\nEC/AI HLEG April 2019 - Hoofdstuk II.1.7.\n4 Risico: Rollen en verantwoordelijkheden zijn niet duidelijk belegd of\nonvoldoende geborgd.\nMaatregel: De rollen en verantwoordelijkheden bij de ontwikkeling en inzet\nvan het algoritme zijn belegd en gedocumenteerd.\n\nToelichting: Duidelijkheid en borging van rollen en verantwoordelijkheden\nzorgen voor een effectief en verantwoord verloop van het proces rondom de\ninzet van een algoritme. Alle relevante belanghebbenden zijn bij de\nontwikkeling en inzet van het algoritme betrokken. Het personeel (intern en\nextern) dat werkt met het algoritme moet over voldoende deskundigheid en\ncompetenties beschikken. Dit moet in ieder geval blijken uit de\nrisicoanalyse, waarbij de organisatie maatregelen neemt om eventuele\ngaten te overbruggen. De organisatie heeft een goed beeld van de\nbeschikbare resources (kwalitatief en kwantitatief) en stuurt daarop.\nBron: EC/AI HLEG April 2019 - Hoofdstuk II.1.5, COBIT APO01.02 / EDM01.\n5 Risico: Het algoritme kan negatieve gevolgen hebben voor grondrechten.\nMaatregel: Onderzoek of het algoritme een ongerechtvaardigde inbreuk\nmaakt op grondrechten (aan de hand van een mensenrechtentoets). Maak\nde consequenties expliciet en leg deze op het juiste niveau vast. Neem\nindien nodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het\nniet inzetten van het algoritme of het (tijdig) stopzetten.\nToelichting: In situaties wanneer dergelijke risico\u2019s bestaan, kan een\neffectbeoordeling worden uitgevoerd wat grondrechten betreft. Dit kan\nvoorafgaand aan de ontwikkeling van het algoritme worden uitgevoerd en\nmoet een evaluatie omvatten van de vraag of de risico\u2019s kunnen worden\nbeperkt of gerechtvaardigd. De afwegingen tussen de verschillende\nbeginselen en rechten moeten zijn vastgesteld en gedocumenteerd.\nBron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1.\n6 Risico: Zonder evaluatie van de kwaliteit van het algoritme is er geen\ngoede sturing, beheersing en verantwoording mogelijk over de inzet van het\nalgoritme.\nMaatregel: Er vindt periodiek een evaluatie plaats van de werking en de\nkwaliteit van het algoritme. Er kunnen namelijk wijzigingen in de werking\nvan het model of de inputdata zijn. De analyse van klachten en incidenten\nis hier ook onderdeel van. Maak de consequenties expliciet en leg deze op\nhet juiste niveau vast. Neem indien nodig tegenmaatregelen. Een ultieme\ntegenmaatregel kan zijn het niet inzetten van het algoritme of het (tijdig)\nstopzetten.\nToelichting: Kwaliteit is o.a. doeltreffendheid, doelmatigheid,\nbetrouwbaarheid en accuraatheid (geschiktheid) en non-discriminatie.\nEvaluatie kan bijvoorbeeld worden gedaan met een peerreview. Een proces\nvoor een periodieke evaluatie van de kwaliteit van het algoritme is\ngedocumenteerd en in werking. De resultaten worden met\nbelanghebbenden gedeeld. De organisatie analyseert of (interne en externe)\nklachten en incidenten het gevolg kunnen zijn van het gebruik van het\nalgoritme. De verantwoordelijke in de business legt verantwoording af over\nde ontwikkeling, inzet en werking van het algoritme.\nBron: EC/AI HLEG April 2019 - Hoofdstuk II.1.2.\n", "norm_risico_namen": ["Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Risico: Zonder eenduidigheid over het doel is geen sturing op enverantwoording over het algoritme mogelijk en is er een groter risico opfouten en/of verschillen in interpretatie.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: De impact van het algoritme is niet inzichtelijk, waardoor niethelder is welke maatregelen moeten worden getroffen om ongewensteeffecten (zoals bias en discriminatie) te voorkomen.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Zonder actueel beeld van risico's kan er geen goede afwegingworden gemaakt of de voordelen van de toepassing van het algoritmeopwegen tegen de nadelen. Risico's worden niet (tijdig) vastgesteld enadequaat geadresseerd en behandeld.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Rollen en verantwoordelijkheden zijn niet duidelijk belegd ofonvoldoende geborgd.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Het algoritme kan negatieve gevolgen hebben voor grondrechten.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Zonder evaluatie van de kwaliteit van het algoritme is er geengoede sturing, beheersing en verantwoording mogelijk over de inzet van hetalgoritme."], "norm_risico_teksten": ["Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Risico: Zonder eenduidigheid over het doel is geen sturing op enverantwoording over het algoritme mogelijk en is er een groter risico opfouten en/of verschillen in interpretatie.Maatregel: Het doel en eventuele subdoelen van het algoritme moeten zospecifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Maak hiervoor gebruik van een multidisciplinaire aanpak en betrek hierbijmeerdere afdelingen en stakeholders. Maak de consequenties expliciet enleg deze op het juiste niveau vast. Neem indien nodig tegenmaatregelen.Een ultieme tegenmaatregel kan zijn het niet inzetten van het algoritme.Toelichting: Het doel van het algoritme moet helder zijn gedefinieerd, ookin relatie tot het maatschappelijke resultaat (outcome), en wordt gedeelddoor de eigenaar, ontwikkelaar en gebruiker van het algoritme. Een bewusteafweging of het algoritme het juiste middel is om het probleem opdoelmatige en doeltreffende wijze op te lossen is gemaakt en vastgelegd.De publieke waarden die met de inzet van algoritmen worden ingegeven,zoals gelijkwaardigheid en veiligheid, maar ook grondrechten die wordengeraakt, zijn ge\u00efnventariseerd en gewogen. Ook de doeltreffendheid,subsidiariteit en proportionaliteit van het in te zetten algoritme zijnafgewogen.Bron: Art. 3.2 Awb (bij besluiten)EC/AI HLEG April 2019 - Hoofdstuk II. 1.1 en 1.7.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: De impact van het algoritme is niet inzichtelijk, waardoor niethelder is welke maatregelen moeten worden getroffen om ongewensteeffecten (zoals bias en discriminatie) te voorkomen.Maatregel: Onderzoek (aan de hand van een mensenrechtentoets) welkegroepen kwetsbaar zijn voor een fout van het algoritme en welke impactdat heeft op deze groepen. Het betreft de \u2018menselijke maat\u2019 bij het nemenvan beslissingen op basis van de output van het algoritme. Maak deconsequenties expliciet en leg deze op het juiste niveau vast. Neem indiennodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn het nietinzetten van het algoritme.Toelichting: Het gaat om zowel de impact op personen of doelgroepen, alsde bredere impact op de samenleving (vanuit sociaal, democratisch enmilieu/ecologisch perspectief).Bron: Art. 3.2 Awb (bij besluiten)EC/AI HLEG April 2019 - Hoofdstuk I. 1.1 & Hoofdstuk II. 1.6.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Zonder actueel beeld van risico's kan er geen goede afwegingworden gemaakt of de voordelen van de toepassing van het algoritmeopwegen tegen de nadelen. Risico's worden niet (tijdig) vastgesteld enadequaat geadresseerd en behandeld.Maatregel: Zorg ervoor dat op vastgelegde (periodieke) momenten eenafweging plaats vindt van de risico\u2019s over het gebruik van het algoritme.Alle stappen van risicomanagement zijn uitgevoerd en op het juiste niveauin de organisatie behandeld, waaronder het identificeren, analyseren,evalueren (t.a.v. risk appetite), behandelen (risicoreactie, o.a.maatregelen), monitoren & beoordelen en communiceren & rapporteren vanrisico's. Maak de consequenties expliciet en leg deze op het juiste niveauvast. Neem indien nodig tegenmaatregelen. Een ultieme tegenmaatregelkan zijn het niet inzetten of (tijdelijk) stopzetten van het algoritme.Toelichting: Het gaat hier om het feit dat er over risico's wordt nagedacht.De organisatie moet beschikken over een ingericht en gedocumenteerdproces voor risicobeheersing.Bron: Art. 3.2 Awb (bij besluiten)COBIT EDM03 / APO12.EC/AI HLEG April 2019 - Hoofdstuk II.1.7.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Rollen en verantwoordelijkheden zijn niet duidelijk belegd ofonvoldoende geborgd.Maatregel: De rollen en verantwoordelijkheden bij de ontwikkeling en inzetvan het algoritme zijn belegd en gedocumenteerd.Toelichting: Duidelijkheid en borging van rollen en verantwoordelijkhedenzorgen voor een effectief en verantwoord verloop van het proces rondom deinzet van een algoritme. Alle relevante belanghebbenden zijn bij deontwikkeling en inzet van het algoritme betrokken. Het personeel (intern enextern) dat werkt met het algoritme moet over voldoende deskundigheid encompetenties beschikken. Dit moet in ieder geval blijken uit derisicoanalyse, waarbij de organisatie maatregelen neemt om eventuelegaten te overbruggen. De organisatie heeft een goed beeld van debeschikbare resources (kwalitatief en kwantitatief) en stuurt daarop.Bron: EC/AI HLEG April 2019 - Hoofdstuk II.1.5, COBIT APO01.02 / EDM01.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Het algoritme kan negatieve gevolgen hebben voor grondrechten.Maatregel: Onderzoek of het algoritme een ongerechtvaardigde inbreukmaakt op grondrechten (aan de hand van een mensenrechtentoets). Maakde consequenties expliciet en leg deze op het juiste niveau vast. Neemindien nodig tegenmaatregelen. Een ultieme tegenmaatregel kan zijn hetniet inzetten van het algoritme of het (tijdig) stopzetten.Toelichting: In situaties wanneer dergelijke risico\u2019s bestaan, kan eeneffectbeoordeling worden uitgevoerd wat grondrechten betreft. Dit kanvoorafgaand aan de ontwikkeling van het algoritme worden uitgevoerd enmoet een evaluatie omvatten van de vraag of de risico\u2019s kunnen wordenbeperkt of gerechtvaardigd. De afwegingen tussen de verschillendebeginselen en rechten moeten zijn vastgesteld en gedocumenteerd.Bron: EC/AI HLEG April 2019 - hoofdstuk II. 1.1.", "Norm: Zorgvuldig handelen bij de ontwikkeling en de inzet algoritmen (zorgvuldigheidsbeginsel) Risico: Zonder evaluatie van de kwaliteit van het algoritme is er geengoede sturing, beheersing en verantwoording mogelijk over de inzet van hetalgoritme.Maatregel: Er vindt periodiek een evaluatie plaats van de werking en dekwaliteit van het algoritme. Er kunnen namelijk wijzigingen in de werkingvan het model of de inputdata zijn. De analyse van klachten en incidentenis hier ook onderdeel van. Maak de consequenties expliciet en leg deze ophet juiste niveau vast. Neem indien nodig tegenmaatregelen. Een ultiemetegenmaatregel kan zijn het niet inzetten van het algoritme of het (tijdig)stopzetten.Toelichting: Kwaliteit is o.a. doeltreffendheid, doelmatigheid,betrouwbaarheid en accuraatheid (geschiktheid) en non-discriminatie.Evaluatie kan bijvoorbeeld worden gedaan met een peerreview. Een procesvoor een periodieke evaluatie van de kwaliteit van het algoritme isgedocumenteerd en in werking. De resultaten worden metbelanghebbenden gedeeld. De organisatie analyseert of (interne en externe)klachten en incidenten het gevolg kunnen zijn van het gebruik van hetalgoritme. De verantwoordelijke in de business legt verantwoording af overde ontwikkeling, inzet en werking van het algoritme.Bron: EC/AI HLEG April 2019 - Hoofdstuk II.1.2."]}, {"waarde_nr": "3.8", "waarde_naam": "Verantwoording", "norm_nr": "3.8.2", "norm_naam": "Motiveer de deugdelijke inzet van algoritmen", "norm_tekst": "Norm: Motiveer de deugdelijke inzet van algoritmen\nRisico: Afhankelijkheid van externe deskundigen die na het ontwikkelen van\nhet algoritme met de betreffende kennis en ervaring weggaan, waardoor\ncontinu\u00efteit en beheersing daarna niet meer gewaarborgd is.\nMaatregelen:\n1. Bij uitbesteding van onderdelen of activiteiten met betrekking tot het\nalgoritme zijn afspraken met betrokken externe partijen gemaakt en\nvastgelegd m.b.t. eigenaarschap, beheer, prestatiecriteria en\nreproduceerbaarheid van het algoritme\n2. De documentatie over het model (ontwerp, werking en voorwaarden) is\nbeschikbaar en begrijpelijk voor ontwikkelaars, gebruikers en de eigenaar\nvan het model.\nToelichting:\n1. Overeenkomst met betreffende partij met afspraken over o.a.\neigenaarschap en beheer (bijv. SLA). Maatregelen om een te grote\nafhankelijkheid te voorkomen moeten zijn beschreven/getroffen, zoals het\nopstellen van een exit-strategie. Bij het maken van afspraken met\nleveranciers moet aandacht zijn voor het risico op vendor lock-in. Hiervan\nis sprake als de opdrachtgever afhankelijk wordt van een externe partij\n(ontwikkelaar), omdat deze niet in staat is om van partij te veranderen\nzonder substanti\u00eble omschakelingskosten of ongemak.\n2. De documentatie moet dusdanig begrijpelijk zijn dat het voor (nieuwe)\nmedewerkers duidelijk is hoe een model gebruikt moet worden (collegiale\nuitlegbaarheid). Ook wanneer de ontwikkelaars van het model niet meer\nbinnen de organisatie werken. Instructies over het gebruik van het model.\nBij medewerkers navragen of de instructies bekend zijn. Het algoritme moet\nuitlegbaar zijn en er moet een afweging plaatsvinden tussen de\nuitlegbaarheid van het model en de prestatie van het model.\nBron:\n1.\nArt. 3.46 Awb (bij besluiten).\nEC/AI HLEG April 2019 - Hoofdstuk II.1.7.\n2.\nEC/AI HLEG April 2019 - hoofdstuk II. 1.1 en 1.4.\n", "norm_risico_namen": ["Norm: Motiveer de deugdelijke inzet van algoritmen Risico: Afhankelijkheid van externe deskundigen die na het ontwikkelen vanhet algoritme met de betreffende kennis en ervaring weggaan, waardoorcontinu\u00efteit en beheersing daarna niet meer gewaarborgd is."], "norm_risico_teksten": ["Norm: Motiveer de deugdelijke inzet van algoritmen Risico: Afhankelijkheid van externe deskundigen die na het ontwikkelen vanhet algoritme met de betreffende kennis en ervaring weggaan, waardoorcontinu\u00efteit en beheersing daarna niet meer gewaarborgd is.Maatregelen:1. Bij uitbesteding van onderdelen of activiteiten met betrekking tot hetalgoritme zijn afspraken met betrokken externe partijen gemaakt envastgelegd m.b.t. eigenaarschap, beheer, prestatiecriteria enreproduceerbaarheid van het algoritme2. De documentatie over het model (ontwerp, werking en voorwaarden) isbeschikbaar en begrijpelijk voor ontwikkelaars, gebruikers en de eigenaarvan het model.Toelichting:1. Overeenkomst met betreffende partij met afspraken over o.a.eigenaarschap en beheer (bijv. SLA). Maatregelen om een te groteafhankelijkheid te voorkomen moeten zijn beschreven/getroffen, zoals hetopstellen van een exit-strategie. Bij het maken van afspraken metleveranciers moet aandacht zijn voor het risico op vendor lock-in. Hiervanis sprake als de opdrachtgever afhankelijk wordt van een externe partij(ontwikkelaar), omdat deze niet in staat is om van partij te veranderenzonder substanti\u00eble omschakelingskosten of ongemak.2. De documentatie moet dusdanig begrijpelijk zijn dat het voor (nieuwe)medewerkers duidelijk is hoe een model gebruikt moet worden (collegialeuitlegbaarheid). Ook wanneer de ontwikkelaars van het model niet meerbinnen de organisatie werken. Instructies over het gebruik van het model.Bij medewerkers navragen of de instructies bekend zijn. Het algoritme moetuitlegbaar zijn en er moet een afweging plaatsvinden tussen deuitlegbaarheid van het model en de prestatie van het model.Bron:1.Art. 3.46 Awb (bij besluiten).EC/AI HLEG April 2019 - Hoofdstuk II.1.7.2.EC/AI HLEG April 2019 - hoofdstuk II. 1.1 en 1.4."]}, {"waarde_nr": "3.8", "waarde_naam": "Verantwoording", "norm_nr": "3.8.3", "norm_naam": "Het algoritme is in goede geordende staat en voldoet aan de Archiefwet 1995, dit betekent dat het algoritme duurzaam toegankelijk is (vindbaar, beschikbaar, leesbaar, interpreteerbaar, betrouwbaar en toekomstbestendig. Voor iedereen die daar recht op heeft en voor zo lang als noodzakelijk", "norm_tekst": "Norm: Het algoritme is in goede geordende staat en voldoet aan de\nArchiefwet 1995, dit betekent dat het algoritme duurzaam toegankelijk is\n(vindbaar, beschikbaar, leesbaar, interpreteerbaar, betrouwbaar en\ntoekomstbestendig. Voor iedereen die daar recht op heeft en voor zo lang\nals noodzakelijk. (*)\nRisico:\nAls informatie over documentatie, trainingsdata, outputdata en logica van\nhet algoritme niet beschikbaar is of niet wordt bijgewerkt, is het niet\nherleidbaar op welke wijze het algoritme functioneert en kan het algoritme\nop een gegeven moment anders functioneren dan gedocumenteerd en is het\nniet helder welke versie van de informatie geldig was op welk moment dat\nhet algoritme is ingezet. .\nMaatregelen:\n1. Het is vastgelegd inclusief beheerprocessen, wat, hoe, hoelang, waar en\nin welke vorm de documentatie, het model (ontwerp, werking en\nvoorwaarden), trainingsdata, output(data) en logica van het algoritme\nbewaard moet worden en beschikbaar moet worden gesteld.\n2. Het is duidelijk welke versie van de documentatie geldig door het gebruik\nvan versiebeheer voor documentatie.\n3. Beheer van documentatie in een gecontroleerde omgeving.\nToelichting:\nAlgoritmen dienen duurzaam toegankelijk te zijn voor het uitvoeren van\noverheidstaken, het afleggen van verantwoording hierover, voor burgers en\nbedrijven in het kader van rechtszekerheid, voor het uitvoeren van\nonderzoek en mogelijk als erfgoed.\nBij de aankoop, bouw, aanpassing, migratie of uitfasering van een algoritme\npas je de eisen van duurzame toegankelijkheid van overheidsinformatie\n(DUTO-eisen) toe. Door ze op te nemen als requirements op het moment\ndat er inrichtingskeuzes voor nieuwe informatiesystemen gemaakt worden.\nOp deze manier wordt archiveren by design toegepast.\nBron:\nArchiefwet 1995, artikel 3, Eisen voor de duurzame toegankelijkheid van\noverheidsinformatie (DUTO-eisen) | Nationaal Archief\n", "norm_risico_namen": ["Norm: Het algoritme is in goede geordende staat en voldoet aan de Archiefwet 1995, dit betekent dat het algoritme duurzaam toegankelijk is (vindbaar, beschikbaar, leesbaar, interpreteerbaar, betrouwbaar en toekomstbestendig. Voor iedereen die daar recht op heeft en voor zo lang als noodzakelijk Risico: Als informatie over documentatie, trainingsdata, outputdata en logica vanhet algoritme niet beschikbaar is of niet wordt bijgewerkt, is het nietherleidbaar op welke wijze het algoritme functioneert en kan het algoritmeop een gegeven moment anders functioneren dan gedocumenteerd en is hetniet helder welke versie van de informatie geldig was op welk moment dathet algoritme is ingezet. ."], "norm_risico_teksten": ["Norm: Het algoritme is in goede geordende staat en voldoet aan de Archiefwet 1995, dit betekent dat het algoritme duurzaam toegankelijk is (vindbaar, beschikbaar, leesbaar, interpreteerbaar, betrouwbaar en toekomstbestendig. Voor iedereen die daar recht op heeft en voor zo lang als noodzakelijk Risico: Als informatie over documentatie, trainingsdata, outputdata en logica vanhet algoritme niet beschikbaar is of niet wordt bijgewerkt, is het nietherleidbaar op welke wijze het algoritme functioneert en kan het algoritmeop een gegeven moment anders functioneren dan gedocumenteerd en is hetniet helder welke versie van de informatie geldig was op welk moment dathet algoritme is ingezet. .Maatregelen:1. Het is vastgelegd inclusief beheerprocessen, wat, hoe, hoelang, waar enin welke vorm de documentatie, het model (ontwerp, werking envoorwaarden), trainingsdata, output(data) en logica van het algoritmebewaard moet worden en beschikbaar moet worden gesteld.2. Het is duidelijk welke versie van de documentatie geldig door het gebruikvan versiebeheer voor documentatie.3. Beheer van documentatie in een gecontroleerde omgeving.Toelichting:Algoritmen dienen duurzaam toegankelijk te zijn voor het uitvoeren vanoverheidstaken, het afleggen van verantwoording hierover, voor burgers enbedrijven in het kader van rechtszekerheid, voor het uitvoeren vanonderzoek en mogelijk als erfgoed.Bij de aankoop, bouw, aanpassing, migratie of uitfasering van een algoritmepas je de eisen van duurzame toegankelijkheid van overheidsinformatie(DUTO-eisen) toe. Door ze op te nemen als requirements op het momentdat er inrichtingskeuzes voor nieuwe informatiesystemen gemaakt worden.Op deze manier wordt archiveren by design toegepast.Bron:Archiefwet 1995, artikel 3, Eisen voor de duurzame toegankelijkheid vanoverheidsinformatie (DUTO-eisen) | Nationaal Archief"]}]